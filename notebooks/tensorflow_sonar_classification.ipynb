{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow with example\n",
    "\n",
    "Thanks to @edureka on youtube.com, I prepared the following notebook for a quick hands-on neural network model for a classification problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Sonar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V52</th>\n",
       "      <th>V53</th>\n",
       "      <th>V54</th>\n",
       "      <th>V55</th>\n",
       "      <th>V56</th>\n",
       "      <th>V57</th>\n",
       "      <th>V58</th>\n",
       "      <th>V59</th>\n",
       "      <th>V60</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       V1      V2      V3      V4      V5      V6      V7      V8      V9  \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "      V10  ...       V52     V53     V54     V55     V56     V57     V58  \\\n",
       "0  0.2111  ...    0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...    0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...    0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...    0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...    0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "      V59     V60  Class  \n",
       "0  0.0090  0.0032      1  \n",
       "1  0.0052  0.0044      1  \n",
       "2  0.0095  0.0078      1  \n",
       "3  0.0040  0.0117      1  \n",
       "4  0.0107  0.0094      1  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparing the sample and labels:** \n",
    "\n",
    "Note the .values applied to df. For later use in tensorflow, X should be an array not a pandas data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis = 1).values\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels, n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_o = one_hot_encode(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y_o, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.3\n",
    "training_epochs = 1500\n",
    "cost_history = np.empty(shape=[1], dtype = float)\n",
    "n_class = 2\n",
    "model_path = \"./dp_model/dp_solar_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a neural network with 6 layers (i.e. 4 hidden layers), with the following dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_0 = X.shape[1] # this is equal to the number of features per sample\n",
    "n_1 = 50 # size of hidden layer 1\n",
    "n_2 = 50 # size of hidden layer 2\n",
    "n_3 = 50 # size of hidden layer 3\n",
    "n_4 = 50 # size of hidden layer 4\n",
    "n_5 = len(np.unique(y)) # this is equal to the number of classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = tf.placeholder(tf.float32, shape=[None, n_0], name = 'x_')\n",
    "yreal_ = tf.placeholder(tf.float32, shape=[None, n_5], name = 'yreal_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, we have 6 layers: 0, 1, 2, 3, 4, 5. The first layer is denoted by $\\boldsymbol{a}^{(0)}$ and the final layer is denoted by $a^{(L)}$ where $L = 5$. So, for each layer $l$, we have: $$\\boldsymbol{a}^l = \\mathrm{W}^l \\boldsymbol{a}^{l - 1} + \\boldsymbol{b}^l.$$\n",
    "\n",
    "Even though for one sample it is convenient to write the linear map as above, with many samples we will rewrite the above forumlat as follows:\n",
    "\\begin{eqnarray}\n",
    "\\boldsymbol{a}^{(1)} = \\boldsymbol{a}^{(l - 1)} \\mathrm{W}^{(1)} + \\boldsymbol{b}^{(1)}\n",
    "\\end{eqnarray}\n",
    "where the dimenstion of $W$ is $n_0 \\times n_1$.\n",
    "\n",
    "Since $\\boldsymbol{a}^{(0)}$ is indeed the input $(x)_{N \\times n_0}$, where $N$ is the number of samples, the above formula reads as: \n",
    "\\begin{eqnarray}\n",
    "\\boldsymbol{a}^{(1)} = \\boldsymbol{x} \\mathrm{W}^{(1)} + \\boldsymbol{b}^{(1)}\n",
    "\\end{eqnarray}\n",
    "Verify that the dimension of $\\boldsymbol{a}^{(1)}$ is $N \\times n_1$.\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\boldsymbol{z}^l = \\boldsymbol{a}^{l - 1}  \\mathrm{W}^l + \\boldsymbol{b}^l\n",
    "\\end{eqnarray}\n",
    "\n",
    "\n",
    "Therefore the dimensions of the weight matrices are as follows:\n",
    "\n",
    "$\\mathrm{W}^1$ is $n_0 \\times n_1$\n",
    "\n",
    "$\\mathrm{W}^2$ is $n_1 \\times n_2$\n",
    "\n",
    "$\\mathrm{W}^3$ is $n_2 \\times n_3$\n",
    "\n",
    "$\\mathrm{W}^4$ is $n_3 \\times n_4$\n",
    "\n",
    "$\\mathrm{W}^5$ is $n_4 \\times n_5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = {\n",
    "    '1' : tf.Variable(tf.truncated_normal([n_0, n_1])), \n",
    "    '2' : tf.Variable(tf.truncated_normal([n_1, n_2])),\n",
    "    '3' : tf.Variable(tf.truncated_normal([n_2, n_3])),\n",
    "    '4' : tf.Variable(tf.truncated_normal([n_3, n_4])),\n",
    "    '5' : tf.Variable(tf.truncated_normal([n_4, n_5]))\n",
    "}\n",
    "b = {\n",
    "    '1' : tf.Variable(tf.truncated_normal([n_1])),\n",
    "    '2' : tf.Variable(tf.truncated_normal([n_2])),\n",
    "    '3' : tf.Variable(tf.truncated_normal([n_3])),\n",
    "    '4' : tf.Variable(tf.truncated_normal([n_4])),\n",
    "    '5' : tf.Variable(tf.truncated_normal([n_5]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to define the hypothesis function of the neural network. That is the formula for the output layer which is found by the sequence of $\\boldsymbol{a}^l =  \\boldsymbol{a}^{l - 1} \\mathrm{W}^l + \\boldsymbol{b}^l$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('layer_1'):\n",
    "    z_1 = tf.add(tf.matmul(x_, w['1']), b['1'])\n",
    "    a_1 = tf.nn.sigmoid(z_1)\n",
    "\n",
    "with tf.variable_scope('layer_2'):\n",
    "    z_2 = tf.add(tf.matmul(a_1, w['2']), b['2'])\n",
    "    a_2 = tf.nn.sigmoid(z_2)\n",
    "\n",
    "with tf.variable_scope('layer_3'):\n",
    "    z_3 = tf.add(tf.matmul(a_2, w['3']), b['3'])\n",
    "    a_3 = tf.nn.sigmoid(z_3)\n",
    "\n",
    "with tf.variable_scope('layer_4'):\n",
    "    z_4 = tf.add(tf.matmul(a_3, w['4']), b['4'])\n",
    "    a_4 = tf.nn.relu(z_4)\n",
    "\n",
    "with tf.variable_scope('output_layer'):\n",
    "    ypred_ = tf.add(tf.matmul(a_4, w['5']), b['5'])\n",
    "#     ypred_ = tf.nn.relu(z_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_function_ = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=ypred_, labels=yreal_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('logging'):\n",
    "    tf.summary.scalar('cost', cost_function_)\n",
    "    summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_step_ = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 60)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_history = []\n",
    "accuracy_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction_ = tf.equal(tf.argmax(yreal_, 1), tf.argmax(ypred_, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_ = tf.reduce_mean(tf.cast(correct_prediction_, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  - cost 92.6898 - accuracy  0.542169\n",
      "epoch:  1  - cost 16.9627 - accuracy  0.457831\n",
      "epoch:  2  - cost 3.58664 - accuracy  0.542169\n",
      "epoch:  3  - cost 6.89485 - accuracy  0.457831\n",
      "epoch:  4  - cost 4.21627 - accuracy  0.542169\n",
      "epoch:  5  - cost 1.5246 - accuracy  0.542169\n",
      "epoch:  6  - cost 1.34745 - accuracy  0.542169\n",
      "epoch:  7  - cost 1.03257 - accuracy  0.542169\n",
      "epoch:  8  - cost 0.690963 - accuracy  0.560241\n",
      "epoch:  9  - cost 0.690577 - accuracy  0.548193\n",
      "epoch:  10  - cost 0.697013 - accuracy  0.481928\n",
      "epoch:  11  - cost 0.730368 - accuracy  0.542169\n",
      "epoch:  12  - cost 0.77141 - accuracy  0.457831\n",
      "epoch:  13  - cost 0.950362 - accuracy  0.542169\n",
      "epoch:  14  - cost 0.687728 - accuracy  0.5\n",
      "epoch:  15  - cost 0.719664 - accuracy  0.542169\n",
      "epoch:  16  - cost 0.74927 - accuracy  0.457831\n",
      "epoch:  17  - cost 0.897182 - accuracy  0.542169\n",
      "epoch:  18  - cost 0.694661 - accuracy  0.457831\n",
      "epoch:  19  - cost 0.751864 - accuracy  0.542169\n",
      "epoch:  20  - cost 0.748449 - accuracy  0.457831\n",
      "epoch:  21  - cost 0.890195 - accuracy  0.542169\n",
      "epoch:  22  - cost 0.67811 - accuracy  0.536145\n",
      "epoch:  23  - cost 0.710261 - accuracy  0.542169\n",
      "epoch:  24  - cost 0.723201 - accuracy  0.457831\n",
      "epoch:  25  - cost 0.833509 - accuracy  0.542169\n",
      "epoch:  26  - cost 0.693208 - accuracy  0.463855\n",
      "epoch:  27  - cost 0.757856 - accuracy  0.542169\n",
      "epoch:  28  - cost 0.715888 - accuracy  0.457831\n",
      "epoch:  29  - cost 0.814893 - accuracy  0.542169\n",
      "epoch:  30  - cost 0.685805 - accuracy  0.475904\n",
      "epoch:  31  - cost 0.741217 - accuracy  0.542169\n",
      "epoch:  32  - cost 0.705119 - accuracy  0.451807\n",
      "epoch:  33  - cost 0.791401 - accuracy  0.542169\n",
      "epoch:  34  - cost 0.68298 - accuracy  0.487952\n",
      "epoch:  35  - cost 0.738742 - accuracy  0.542169\n",
      "epoch:  36  - cost 0.693469 - accuracy  0.475904\n",
      "epoch:  37  - cost 0.767439 - accuracy  0.542169\n",
      "epoch:  38  - cost 0.680436 - accuracy  0.53012\n",
      "epoch:  39  - cost 0.73713 - accuracy  0.542169\n",
      "epoch:  40  - cost 0.683386 - accuracy  0.512048\n",
      "epoch:  41  - cost 0.747646 - accuracy  0.542169\n",
      "epoch:  42  - cost 0.676313 - accuracy  0.548193\n",
      "epoch:  43  - cost 0.732857 - accuracy  0.542169\n",
      "epoch:  44  - cost 0.675443 - accuracy  0.548193\n",
      "epoch:  45  - cost 0.734476 - accuracy  0.542169\n",
      "epoch:  46  - cost 0.670479 - accuracy  0.554217\n",
      "epoch:  47  - cost 0.725162 - accuracy  0.542169\n",
      "epoch:  48  - cost 0.668222 - accuracy  0.566265\n",
      "epoch:  49  - cost 0.723848 - accuracy  0.542169\n",
      "epoch:  50  - cost 0.664623 - accuracy  0.572289\n",
      "epoch:  51  - cost 0.718155 - accuracy  0.542169\n",
      "epoch:  52  - cost 0.661698 - accuracy  0.584337\n",
      "epoch:  53  - cost 0.714803 - accuracy  0.542169\n",
      "epoch:  54  - cost 0.658312 - accuracy  0.596386\n",
      "epoch:  55  - cost 0.71032 - accuracy  0.542169\n",
      "epoch:  56  - cost 0.653663 - accuracy  0.60241\n",
      "epoch:  57  - cost 0.703972 - accuracy  0.548193\n",
      "epoch:  58  - cost 0.652947 - accuracy  0.60241\n",
      "epoch:  59  - cost 0.705918 - accuracy  0.548193\n",
      "epoch:  60  - cost 0.649912 - accuracy  0.590361\n",
      "epoch:  61  - cost 0.701143 - accuracy  0.548193\n",
      "epoch:  62  - cost 0.645315 - accuracy  0.590361\n",
      "epoch:  63  - cost 0.694143 - accuracy  0.554217\n",
      "epoch:  64  - cost 0.642214 - accuracy  0.596386\n",
      "epoch:  65  - cost 0.690644 - accuracy  0.560241\n",
      "epoch:  66  - cost 0.638741 - accuracy  0.608434\n",
      "epoch:  67  - cost 0.687349 - accuracy  0.560241\n",
      "epoch:  68  - cost 0.638386 - accuracy  0.60241\n",
      "epoch:  69  - cost 0.689231 - accuracy  0.560241\n",
      "epoch:  70  - cost 0.636247 - accuracy  0.60241\n",
      "epoch:  71  - cost 0.685815 - accuracy  0.560241\n",
      "epoch:  72  - cost 0.632046 - accuracy  0.626506\n",
      "epoch:  73  - cost 0.678095 - accuracy  0.560241\n",
      "epoch:  74  - cost 0.628904 - accuracy  0.63253\n",
      "epoch:  75  - cost 0.675155 - accuracy  0.560241\n",
      "epoch:  76  - cost 0.627164 - accuracy  0.63253\n",
      "epoch:  77  - cost 0.674582 - accuracy  0.560241\n",
      "epoch:  78  - cost 0.624539 - accuracy  0.620482\n",
      "epoch:  79  - cost 0.670596 - accuracy  0.560241\n",
      "epoch:  80  - cost 0.621612 - accuracy  0.63253\n",
      "epoch:  81  - cost 0.666663 - accuracy  0.560241\n",
      "epoch:  82  - cost 0.619885 - accuracy  0.63253\n",
      "epoch:  83  - cost 0.664893 - accuracy  0.566265\n",
      "epoch:  84  - cost 0.616523 - accuracy  0.63253\n",
      "epoch:  85  - cost 0.659545 - accuracy  0.584337\n",
      "epoch:  86  - cost 0.612912 - accuracy  0.650602\n",
      "epoch:  87  - cost 0.656218 - accuracy  0.584337\n",
      "epoch:  88  - cost 0.609941 - accuracy  0.650602\n",
      "epoch:  89  - cost 0.654644 - accuracy  0.584337\n",
      "epoch:  90  - cost 0.611239 - accuracy  0.650602\n",
      "epoch:  91  - cost 0.658308 - accuracy  0.578313\n",
      "epoch:  92  - cost 0.600343 - accuracy  0.668675\n",
      "epoch:  93  - cost 0.635836 - accuracy  0.608434\n",
      "epoch:  94  - cost 0.601976 - accuracy  0.662651\n",
      "epoch:  95  - cost 0.649815 - accuracy  0.590361\n",
      "epoch:  96  - cost 0.594934 - accuracy  0.680723\n",
      "epoch:  97  - cost 0.638532 - accuracy  0.614458\n",
      "epoch:  98  - cost 0.59557 - accuracy  0.674699\n",
      "epoch:  99  - cost 0.646034 - accuracy  0.60241\n",
      "epoch:  100  - cost 0.587625 - accuracy  0.692771\n",
      "epoch:  101  - cost 0.632204 - accuracy  0.626506\n",
      "epoch:  102  - cost 0.587101 - accuracy  0.698795\n",
      "epoch:  103  - cost 0.640892 - accuracy  0.620482\n",
      "epoch:  104  - cost 0.577457 - accuracy  0.698795\n",
      "epoch:  105  - cost 0.622807 - accuracy  0.650602\n",
      "epoch:  106  - cost 0.581201 - accuracy  0.692771\n",
      "epoch:  107  - cost 0.64106 - accuracy  0.620482\n",
      "epoch:  108  - cost 0.572514 - accuracy  0.704819\n",
      "epoch:  109  - cost 0.623109 - accuracy  0.656627\n",
      "epoch:  110  - cost 0.576995 - accuracy  0.698795\n",
      "epoch:  111  - cost 0.641708 - accuracy  0.63253\n",
      "epoch:  112  - cost 0.566528 - accuracy  0.704819\n",
      "epoch:  113  - cost 0.618082 - accuracy  0.662651\n",
      "epoch:  114  - cost 0.57457 - accuracy  0.692771\n",
      "epoch:  115  - cost 0.641215 - accuracy  0.63253\n",
      "epoch:  116  - cost 0.563968 - accuracy  0.704819\n",
      "epoch:  117  - cost 0.616597 - accuracy  0.662651\n",
      "epoch:  118  - cost 0.56653 - accuracy  0.704819\n",
      "epoch:  119  - cost 0.624156 - accuracy  0.662651\n",
      "epoch:  120  - cost 0.563122 - accuracy  0.704819\n",
      "epoch:  121  - cost 0.61535 - accuracy  0.662651\n",
      "epoch:  122  - cost 0.56455 - accuracy  0.698795\n",
      "epoch:  123  - cost 0.623189 - accuracy  0.662651\n",
      "epoch:  124  - cost 0.559541 - accuracy  0.704819\n",
      "epoch:  125  - cost 0.60742 - accuracy  0.668675\n",
      "epoch:  126  - cost 0.55497 - accuracy  0.710843\n",
      "epoch:  127  - cost 0.602693 - accuracy  0.668675\n",
      "epoch:  128  - cost 0.555083 - accuracy  0.710843\n",
      "epoch:  129  - cost 0.605983 - accuracy  0.668675\n",
      "epoch:  130  - cost 0.556096 - accuracy  0.716867\n",
      "epoch:  131  - cost 0.605893 - accuracy  0.668675\n",
      "epoch:  132  - cost 0.550201 - accuracy  0.716867\n",
      "epoch:  133  - cost 0.59349 - accuracy  0.674699\n",
      "epoch:  134  - cost 0.543616 - accuracy  0.722892\n",
      "epoch:  135  - cost 0.584699 - accuracy  0.686747\n",
      "epoch:  136  - cost 0.547095 - accuracy  0.722892\n",
      "epoch:  137  - cost 0.596482 - accuracy  0.674699\n",
      "epoch:  138  - cost 0.541618 - accuracy  0.722892\n",
      "epoch:  139  - cost 0.578042 - accuracy  0.686747\n",
      "epoch:  140  - cost 0.535525 - accuracy  0.722892\n",
      "epoch:  141  - cost 0.579272 - accuracy  0.686747\n",
      "epoch:  142  - cost 0.549487 - accuracy  0.728916\n",
      "epoch:  143  - cost 0.607781 - accuracy  0.674699\n",
      "epoch:  144  - cost 0.520149 - accuracy  0.753012\n",
      "epoch:  145  - cost 0.534933 - accuracy  0.73494\n",
      "epoch:  146  - cost 0.514776 - accuracy  0.753012\n",
      "epoch:  147  - cost 0.553608 - accuracy  0.710843\n",
      "epoch:  148  - cost 0.555251 - accuracy  0.73494\n",
      "epoch:  149  - cost 0.647794 - accuracy  0.644578\n",
      "epoch:  150  - cost 0.50205 - accuracy  0.759036\n",
      "epoch:  151  - cost 0.503036 - accuracy  0.746988\n",
      "epoch:  152  - cost 0.48642 - accuracy  0.783133\n",
      "epoch:  153  - cost 0.496529 - accuracy  0.759036\n",
      "epoch:  154  - cost 0.503435 - accuracy  0.746988\n",
      "epoch:  155  - cost 0.573353 - accuracy  0.698795\n",
      "epoch:  156  - cost 0.591313 - accuracy  0.692771\n",
      "epoch:  157  - cost 0.717021 - accuracy  0.578313\n",
      "epoch:  158  - cost 0.485582 - accuracy  0.801205\n",
      "epoch:  159  - cost 0.475153 - accuracy  0.777108\n",
      "epoch:  160  - cost 0.470299 - accuracy  0.813253\n",
      "epoch:  161  - cost 0.463752 - accuracy  0.795181\n",
      "epoch:  162  - cost 0.472255 - accuracy  0.795181\n",
      "epoch:  163  - cost 0.496278 - accuracy  0.76506\n",
      "epoch:  164  - cost 0.620437 - accuracy  0.674699\n",
      "epoch:  165  - cost 0.641416 - accuracy  0.656627\n",
      "epoch:  166  - cost 0.755954 - accuracy  0.554217\n",
      "epoch:  167  - cost 0.560242 - accuracy  0.692771\n",
      "epoch:  168  - cost 0.473512 - accuracy  0.789157\n",
      "epoch:  169  - cost 0.463801 - accuracy  0.813253\n",
      "epoch:  170  - cost 0.454434 - accuracy  0.795181\n",
      "epoch:  171  - cost 0.455335 - accuracy  0.801205\n",
      "epoch:  172  - cost 0.466919 - accuracy  0.789157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  173  - cost 0.526202 - accuracy  0.722892\n",
      "epoch:  174  - cost 0.605543 - accuracy  0.686747\n",
      "epoch:  175  - cost 0.795854 - accuracy  0.560241\n",
      "epoch:  176  - cost 0.508777 - accuracy  0.759036\n",
      "epoch:  177  - cost 0.484575 - accuracy  0.789157\n",
      "epoch:  178  - cost 0.483222 - accuracy  0.789157\n",
      "epoch:  179  - cost 0.469631 - accuracy  0.777108\n",
      "epoch:  180  - cost 0.473406 - accuracy  0.771084\n",
      "epoch:  181  - cost 0.472984 - accuracy  0.789157\n",
      "epoch:  182  - cost 0.512514 - accuracy  0.728916\n",
      "epoch:  183  - cost 0.522413 - accuracy  0.759036\n",
      "epoch:  184  - cost 0.634095 - accuracy  0.668675\n",
      "epoch:  185  - cost 0.451199 - accuracy  0.819277\n",
      "epoch:  186  - cost 0.442119 - accuracy  0.813253\n",
      "epoch:  187  - cost 0.437609 - accuracy  0.807229\n",
      "epoch:  188  - cost 0.44786 - accuracy  0.795181\n",
      "epoch:  189  - cost 0.475426 - accuracy  0.771084\n",
      "epoch:  190  - cost 0.606613 - accuracy  0.698795\n",
      "epoch:  191  - cost 0.561365 - accuracy  0.759036\n",
      "epoch:  192  - cost 0.683008 - accuracy  0.608434\n",
      "epoch:  193  - cost 0.462826 - accuracy  0.801205\n",
      "epoch:  194  - cost 0.450019 - accuracy  0.777108\n",
      "epoch:  195  - cost 0.461029 - accuracy  0.771084\n",
      "epoch:  196  - cost 0.460181 - accuracy  0.777108\n",
      "epoch:  197  - cost 0.543344 - accuracy  0.704819\n",
      "epoch:  198  - cost 0.54546 - accuracy  0.76506\n",
      "epoch:  199  - cost 0.663265 - accuracy  0.63253\n",
      "epoch:  200  - cost 0.447206 - accuracy  0.813253\n",
      "epoch:  201  - cost 0.430307 - accuracy  0.837349\n",
      "epoch:  202  - cost 0.430596 - accuracy  0.807229\n",
      "epoch:  203  - cost 0.434739 - accuracy  0.795181\n",
      "epoch:  204  - cost 0.474091 - accuracy  0.76506\n",
      "epoch:  205  - cost 0.530569 - accuracy  0.771084\n",
      "epoch:  206  - cost 0.710663 - accuracy  0.608434\n",
      "epoch:  207  - cost 0.44306 - accuracy  0.825301\n",
      "epoch:  208  - cost 0.432407 - accuracy  0.831325\n",
      "epoch:  209  - cost 0.420241 - accuracy  0.831325\n",
      "epoch:  210  - cost 0.412268 - accuracy  0.849398\n",
      "epoch:  211  - cost 0.419248 - accuracy  0.807229\n",
      "epoch:  212  - cost 0.441162 - accuracy  0.789157\n",
      "epoch:  213  - cost 0.548524 - accuracy  0.704819\n",
      "epoch:  214  - cost 0.531667 - accuracy  0.771084\n",
      "epoch:  215  - cost 0.652337 - accuracy  0.63253\n",
      "epoch:  216  - cost 0.425719 - accuracy  0.813253\n",
      "epoch:  217  - cost 0.408001 - accuracy  0.849398\n",
      "epoch:  218  - cost 0.417026 - accuracy  0.807229\n",
      "epoch:  219  - cost 0.424903 - accuracy  0.783133\n",
      "epoch:  220  - cost 0.493129 - accuracy  0.753012\n",
      "epoch:  221  - cost 0.537003 - accuracy  0.759036\n",
      "epoch:  222  - cost 0.726221 - accuracy  0.60241\n",
      "epoch:  223  - cost 0.438156 - accuracy  0.807229\n",
      "epoch:  224  - cost 0.425716 - accuracy  0.843373\n",
      "epoch:  225  - cost 0.418781 - accuracy  0.819277\n",
      "epoch:  226  - cost 0.408959 - accuracy  0.819277\n",
      "epoch:  227  - cost 0.437682 - accuracy  0.777108\n",
      "epoch:  228  - cost 0.475768 - accuracy  0.789157\n",
      "epoch:  229  - cost 0.656735 - accuracy  0.674699\n",
      "epoch:  230  - cost 0.416502 - accuracy  0.837349\n",
      "epoch:  231  - cost 0.408541 - accuracy  0.831325\n",
      "epoch:  232  - cost 0.400128 - accuracy  0.819277\n",
      "epoch:  233  - cost 0.433141 - accuracy  0.777108\n",
      "epoch:  234  - cost 0.457238 - accuracy  0.789157\n",
      "epoch:  235  - cost 0.629433 - accuracy  0.674699\n",
      "epoch:  236  - cost 0.406025 - accuracy  0.855422\n",
      "epoch:  237  - cost 0.391403 - accuracy  0.825301\n",
      "epoch:  238  - cost 0.384003 - accuracy  0.837349\n",
      "epoch:  239  - cost 0.405089 - accuracy  0.819277\n",
      "epoch:  240  - cost 0.4494 - accuracy  0.801205\n",
      "epoch:  241  - cost 0.65186 - accuracy  0.674699\n",
      "epoch:  242  - cost 0.419638 - accuracy  0.819277\n",
      "epoch:  243  - cost 0.425983 - accuracy  0.789157\n",
      "epoch:  244  - cost 0.409409 - accuracy  0.789157\n",
      "epoch:  245  - cost 0.479025 - accuracy  0.746988\n",
      "epoch:  246  - cost 0.443241 - accuracy  0.795181\n",
      "epoch:  247  - cost 0.573223 - accuracy  0.680723\n",
      "epoch:  248  - cost 0.38191 - accuracy  0.86747\n",
      "epoch:  249  - cost 0.368955 - accuracy  0.837349\n",
      "epoch:  250  - cost 0.375547 - accuracy  0.831325\n",
      "epoch:  251  - cost 0.415583 - accuracy  0.813253\n",
      "epoch:  252  - cost 0.463881 - accuracy  0.789157\n",
      "epoch:  253  - cost 0.692799 - accuracy  0.656627\n",
      "epoch:  254  - cost 0.406682 - accuracy  0.849398\n",
      "epoch:  255  - cost 0.388109 - accuracy  0.843373\n",
      "epoch:  256  - cost 0.370858 - accuracy  0.849398\n",
      "epoch:  257  - cost 0.388443 - accuracy  0.819277\n",
      "epoch:  258  - cost 0.430207 - accuracy  0.795181\n",
      "epoch:  259  - cost 0.600625 - accuracy  0.680723\n",
      "epoch:  260  - cost 0.389789 - accuracy  0.831325\n",
      "epoch:  261  - cost 0.384765 - accuracy  0.831325\n",
      "epoch:  262  - cost 0.399065 - accuracy  0.789157\n",
      "epoch:  263  - cost 0.511962 - accuracy  0.722892\n",
      "epoch:  264  - cost 0.400184 - accuracy  0.783133\n",
      "epoch:  265  - cost 0.486626 - accuracy  0.73494\n",
      "epoch:  266  - cost 0.384018 - accuracy  0.825301\n",
      "epoch:  267  - cost 0.426579 - accuracy  0.777108\n",
      "epoch:  268  - cost 0.396739 - accuracy  0.795181\n",
      "epoch:  269  - cost 0.513918 - accuracy  0.728916\n",
      "epoch:  270  - cost 0.402094 - accuracy  0.783133\n",
      "epoch:  271  - cost 0.463298 - accuracy  0.73494\n",
      "epoch:  272  - cost 0.377919 - accuracy  0.819277\n",
      "epoch:  273  - cost 0.417523 - accuracy  0.783133\n",
      "epoch:  274  - cost 0.403326 - accuracy  0.801205\n",
      "epoch:  275  - cost 0.536464 - accuracy  0.710843\n",
      "epoch:  276  - cost 0.38251 - accuracy  0.831325\n",
      "epoch:  277  - cost 0.392946 - accuracy  0.813253\n",
      "epoch:  278  - cost 0.395635 - accuracy  0.801205\n",
      "epoch:  279  - cost 0.515895 - accuracy  0.716867\n",
      "epoch:  280  - cost 0.392373 - accuracy  0.783133\n",
      "epoch:  281  - cost 0.429885 - accuracy  0.76506\n",
      "epoch:  282  - cost 0.382482 - accuracy  0.801205\n",
      "epoch:  283  - cost 0.445412 - accuracy  0.753012\n",
      "epoch:  284  - cost 0.398715 - accuracy  0.807229\n",
      "epoch:  285  - cost 0.498425 - accuracy  0.716867\n",
      "epoch:  286  - cost 0.375929 - accuracy  0.819277\n",
      "epoch:  287  - cost 0.388543 - accuracy  0.825301\n",
      "epoch:  288  - cost 0.386284 - accuracy  0.825301\n",
      "epoch:  289  - cost 0.490381 - accuracy  0.728916\n",
      "epoch:  290  - cost 0.376129 - accuracy  0.813253\n",
      "epoch:  291  - cost 0.401789 - accuracy  0.801205\n",
      "epoch:  292  - cost 0.390461 - accuracy  0.813253\n",
      "epoch:  293  - cost 0.502655 - accuracy  0.716867\n",
      "epoch:  294  - cost 0.373325 - accuracy  0.831325\n",
      "epoch:  295  - cost 0.380143 - accuracy  0.825301\n",
      "epoch:  296  - cost 0.374512 - accuracy  0.819277\n",
      "epoch:  297  - cost 0.475343 - accuracy  0.740964\n",
      "epoch:  298  - cost 0.374918 - accuracy  0.813253\n",
      "epoch:  299  - cost 0.413616 - accuracy  0.783133\n",
      "epoch:  300  - cost 0.396284 - accuracy  0.813253\n",
      "epoch:  301  - cost 0.521431 - accuracy  0.716867\n",
      "epoch:  302  - cost 0.369387 - accuracy  0.837349\n",
      "epoch:  303  - cost 0.355224 - accuracy  0.837349\n",
      "epoch:  304  - cost 0.356782 - accuracy  0.819277\n",
      "epoch:  305  - cost 0.435125 - accuracy  0.753012\n",
      "epoch:  306  - cost 0.39594 - accuracy  0.819277\n",
      "epoch:  307  - cost 0.518493 - accuracy  0.704819\n",
      "epoch:  308  - cost 0.364013 - accuracy  0.837349\n",
      "epoch:  309  - cost 0.346748 - accuracy  0.849398\n",
      "epoch:  310  - cost 0.34406 - accuracy  0.825301\n",
      "epoch:  311  - cost 0.412029 - accuracy  0.795181\n",
      "epoch:  312  - cost 0.41003 - accuracy  0.819277\n",
      "epoch:  313  - cost 0.585635 - accuracy  0.686747\n",
      "epoch:  314  - cost 0.380184 - accuracy  0.855422\n",
      "epoch:  315  - cost 0.345714 - accuracy  0.855422\n",
      "epoch:  316  - cost 0.33492 - accuracy  0.837349\n",
      "epoch:  317  - cost 0.368815 - accuracy  0.837349\n",
      "epoch:  318  - cost 0.374817 - accuracy  0.813253\n",
      "epoch:  319  - cost 0.517407 - accuracy  0.710843\n",
      "epoch:  320  - cost 0.368082 - accuracy  0.831325\n",
      "epoch:  321  - cost 0.363153 - accuracy  0.831325\n",
      "epoch:  322  - cost 0.332794 - accuracy  0.837349\n",
      "epoch:  323  - cost 0.372634 - accuracy  0.831325\n",
      "epoch:  324  - cost 0.383528 - accuracy  0.807229\n",
      "epoch:  325  - cost 0.546849 - accuracy  0.692771\n",
      "epoch:  326  - cost 0.351131 - accuracy  0.861446\n",
      "epoch:  327  - cost 0.328402 - accuracy  0.849398\n",
      "epoch:  328  - cost 0.321485 - accuracy  0.855422\n",
      "epoch:  329  - cost 0.352874 - accuracy  0.843373\n",
      "epoch:  330  - cost 0.380943 - accuracy  0.813253\n",
      "epoch:  331  - cost 0.564491 - accuracy  0.698795\n",
      "epoch:  332  - cost 0.376533 - accuracy  0.837349\n",
      "epoch:  333  - cost 0.356454 - accuracy  0.843373\n",
      "epoch:  334  - cost 0.323228 - accuracy  0.849398\n",
      "epoch:  335  - cost 0.344634 - accuracy  0.843373\n",
      "epoch:  336  - cost 0.344791 - accuracy  0.813253\n",
      "epoch:  337  - cost 0.45365 - accuracy  0.740964\n",
      "epoch:  338  - cost 0.373157 - accuracy  0.813253\n",
      "epoch:  339  - cost 0.455853 - accuracy  0.722892\n",
      "epoch:  340  - cost 0.328822 - accuracy  0.849398\n",
      "epoch:  341  - cost 0.327155 - accuracy  0.86747\n",
      "epoch:  342  - cost 0.324696 - accuracy  0.843373\n",
      "epoch:  343  - cost 0.389176 - accuracy  0.825301\n",
      "epoch:  344  - cost 0.405007 - accuracy  0.819277\n",
      "epoch:  345  - cost 0.619497 - accuracy  0.680723\n",
      "epoch:  346  - cost 0.374299 - accuracy  0.849398\n",
      "epoch:  347  - cost 0.324949 - accuracy  0.86747\n",
      "epoch:  348  - cost 0.301766 - accuracy  0.891566\n",
      "epoch:  349  - cost 0.297912 - accuracy  0.86747\n",
      "epoch:  350  - cost 0.300874 - accuracy  0.861446\n",
      "epoch:  351  - cost 0.344005 - accuracy  0.837349\n",
      "epoch:  352  - cost 0.368321 - accuracy  0.813253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  353  - cost 0.567584 - accuracy  0.698795\n",
      "epoch:  354  - cost 0.356503 - accuracy  0.855422\n",
      "epoch:  355  - cost 0.343208 - accuracy  0.849398\n",
      "epoch:  356  - cost 0.312174 - accuracy  0.861446\n",
      "epoch:  357  - cost 0.343758 - accuracy  0.837349\n",
      "epoch:  358  - cost 0.334293 - accuracy  0.831325\n",
      "epoch:  359  - cost 0.451308 - accuracy  0.73494\n",
      "epoch:  360  - cost 0.382126 - accuracy  0.807229\n",
      "epoch:  361  - cost 0.478123 - accuracy  0.710843\n",
      "epoch:  362  - cost 0.310507 - accuracy  0.879518\n",
      "epoch:  363  - cost 0.290138 - accuracy  0.873494\n",
      "epoch:  364  - cost 0.290184 - accuracy  0.86747\n",
      "epoch:  365  - cost 0.317579 - accuracy  0.86747\n",
      "epoch:  366  - cost 0.338795 - accuracy  0.819277\n",
      "epoch:  367  - cost 0.49603 - accuracy  0.722892\n",
      "epoch:  368  - cost 0.40692 - accuracy  0.783133\n",
      "epoch:  369  - cost 0.485142 - accuracy  0.710843\n",
      "epoch:  370  - cost 0.298928 - accuracy  0.891566\n",
      "epoch:  371  - cost 0.279665 - accuracy  0.879518\n",
      "epoch:  372  - cost 0.271639 - accuracy  0.891566\n",
      "epoch:  373  - cost 0.266764 - accuracy  0.891566\n",
      "epoch:  374  - cost 0.263795 - accuracy  0.89759\n",
      "epoch:  375  - cost 0.262158 - accuracy  0.879518\n",
      "epoch:  376  - cost 0.266622 - accuracy  0.903614\n",
      "epoch:  377  - cost 0.297042 - accuracy  0.861446\n",
      "epoch:  378  - cost 0.390045 - accuracy  0.819277\n",
      "epoch:  379  - cost 0.782419 - accuracy  0.656627\n",
      "epoch:  380  - cost 0.507414 - accuracy  0.777108\n",
      "epoch:  381  - cost 0.508695 - accuracy  0.710843\n",
      "epoch:  382  - cost 0.336221 - accuracy  0.891566\n",
      "epoch:  383  - cost 0.30274 - accuracy  0.89759\n",
      "epoch:  384  - cost 0.295655 - accuracy  0.86747\n",
      "epoch:  385  - cost 0.305056 - accuracy  0.861446\n",
      "epoch:  386  - cost 0.387752 - accuracy  0.813253\n",
      "epoch:  387  - cost 0.371907 - accuracy  0.825301\n",
      "epoch:  388  - cost 0.528005 - accuracy  0.716867\n",
      "epoch:  389  - cost 0.309225 - accuracy  0.873494\n",
      "epoch:  390  - cost 0.285886 - accuracy  0.885542\n",
      "epoch:  391  - cost 0.285663 - accuracy  0.891566\n",
      "epoch:  392  - cost 0.329581 - accuracy  0.843373\n",
      "epoch:  393  - cost 0.315454 - accuracy  0.855422\n",
      "epoch:  394  - cost 0.445145 - accuracy  0.759036\n",
      "epoch:  395  - cost 0.386573 - accuracy  0.801205\n",
      "epoch:  396  - cost 0.477766 - accuracy  0.716867\n",
      "epoch:  397  - cost 0.291913 - accuracy  0.885542\n",
      "epoch:  398  - cost 0.268949 - accuracy  0.89759\n",
      "epoch:  399  - cost 0.261627 - accuracy  0.89759\n",
      "epoch:  400  - cost 0.261043 - accuracy  0.885542\n",
      "epoch:  401  - cost 0.271356 - accuracy  0.873494\n",
      "epoch:  402  - cost 0.330826 - accuracy  0.843373\n",
      "epoch:  403  - cost 0.354322 - accuracy  0.819277\n",
      "epoch:  404  - cost 0.567065 - accuracy  0.704819\n",
      "epoch:  405  - cost 0.350058 - accuracy  0.873494\n",
      "epoch:  406  - cost 0.330217 - accuracy  0.855422\n",
      "epoch:  407  - cost 0.283005 - accuracy  0.891566\n",
      "epoch:  408  - cost 0.308129 - accuracy  0.861446\n",
      "epoch:  409  - cost 0.29697 - accuracy  0.86747\n",
      "epoch:  410  - cost 0.401772 - accuracy  0.795181\n",
      "epoch:  411  - cost 0.381054 - accuracy  0.807229\n",
      "epoch:  412  - cost 0.526599 - accuracy  0.698795\n",
      "epoch:  413  - cost 0.293436 - accuracy  0.89759\n",
      "epoch:  414  - cost 0.263528 - accuracy  0.903614\n",
      "epoch:  415  - cost 0.251295 - accuracy  0.891566\n",
      "epoch:  416  - cost 0.249591 - accuracy  0.89759\n",
      "epoch:  417  - cost 0.249308 - accuracy  0.891566\n",
      "epoch:  418  - cost 0.26769 - accuracy  0.873494\n",
      "epoch:  419  - cost 0.310631 - accuracy  0.849398\n",
      "epoch:  420  - cost 0.513825 - accuracy  0.73494\n",
      "epoch:  421  - cost 0.423317 - accuracy  0.789157\n",
      "epoch:  422  - cost 0.481146 - accuracy  0.728916\n",
      "epoch:  423  - cost 0.271885 - accuracy  0.909639\n",
      "epoch:  424  - cost 0.250591 - accuracy  0.909639\n",
      "epoch:  425  - cost 0.24157 - accuracy  0.909639\n",
      "epoch:  426  - cost 0.238806 - accuracy  0.89759\n",
      "epoch:  427  - cost 0.243117 - accuracy  0.885542\n",
      "epoch:  428  - cost 0.261364 - accuracy  0.885542\n",
      "epoch:  429  - cost 0.359281 - accuracy  0.837349\n",
      "epoch:  430  - cost 0.38315 - accuracy  0.819277\n",
      "epoch:  431  - cost 0.695343 - accuracy  0.668675\n",
      "epoch:  432  - cost 0.39411 - accuracy  0.849398\n",
      "epoch:  433  - cost 0.3266 - accuracy  0.873494\n",
      "epoch:  434  - cost 0.282433 - accuracy  0.891566\n",
      "epoch:  435  - cost 0.273444 - accuracy  0.89759\n",
      "epoch:  436  - cost 0.258237 - accuracy  0.891566\n",
      "epoch:  437  - cost 0.265702 - accuracy  0.873494\n",
      "epoch:  438  - cost 0.291385 - accuracy  0.861446\n",
      "epoch:  439  - cost 0.424049 - accuracy  0.771084\n",
      "epoch:  440  - cost 0.32718 - accuracy  0.855422\n",
      "epoch:  441  - cost 0.377325 - accuracy  0.807229\n",
      "epoch:  442  - cost 0.275012 - accuracy  0.879518\n",
      "epoch:  443  - cost 0.329836 - accuracy  0.843373\n",
      "epoch:  444  - cost 0.271517 - accuracy  0.891566\n",
      "epoch:  445  - cost 0.309273 - accuracy  0.855422\n",
      "epoch:  446  - cost 0.329058 - accuracy  0.849398\n",
      "epoch:  447  - cost 0.532227 - accuracy  0.722892\n",
      "epoch:  448  - cost 0.336532 - accuracy  0.861446\n",
      "epoch:  449  - cost 0.28817 - accuracy  0.86747\n",
      "epoch:  450  - cost 0.257308 - accuracy  0.903614\n",
      "epoch:  451  - cost 0.269131 - accuracy  0.873494\n",
      "epoch:  452  - cost 0.27038 - accuracy  0.891566\n",
      "epoch:  453  - cost 0.370451 - accuracy  0.813253\n",
      "epoch:  454  - cost 0.32655 - accuracy  0.825301\n",
      "epoch:  455  - cost 0.435666 - accuracy  0.753012\n",
      "epoch:  456  - cost 0.254413 - accuracy  0.915663\n",
      "epoch:  457  - cost 0.234696 - accuracy  0.909639\n",
      "epoch:  458  - cost 0.230441 - accuracy  0.909639\n",
      "epoch:  459  - cost 0.244044 - accuracy  0.89759\n",
      "epoch:  460  - cost 0.264241 - accuracy  0.879518\n",
      "epoch:  461  - cost 0.401119 - accuracy  0.789157\n",
      "epoch:  462  - cost 0.351062 - accuracy  0.813253\n",
      "epoch:  463  - cost 0.471815 - accuracy  0.740964\n",
      "epoch:  464  - cost 0.260851 - accuracy  0.909639\n",
      "epoch:  465  - cost 0.236996 - accuracy  0.915663\n",
      "epoch:  466  - cost 0.230442 - accuracy  0.903614\n",
      "epoch:  467  - cost 0.248512 - accuracy  0.89759\n",
      "epoch:  468  - cost 0.266457 - accuracy  0.885542\n",
      "epoch:  469  - cost 0.404598 - accuracy  0.783133\n",
      "epoch:  470  - cost 0.349027 - accuracy  0.813253\n",
      "epoch:  471  - cost 0.425704 - accuracy  0.76506\n",
      "epoch:  472  - cost 0.236482 - accuracy  0.927711\n",
      "epoch:  473  - cost 0.225677 - accuracy  0.915663\n",
      "epoch:  474  - cost 0.219776 - accuracy  0.915663\n",
      "epoch:  475  - cost 0.237622 - accuracy  0.89759\n",
      "epoch:  476  - cost 0.268024 - accuracy  0.879518\n",
      "epoch:  477  - cost 0.434794 - accuracy  0.76506\n",
      "epoch:  478  - cost 0.443405 - accuracy  0.801205\n",
      "epoch:  479  - cost 0.63274 - accuracy  0.638554\n",
      "epoch:  480  - cost 0.290041 - accuracy  0.915663\n",
      "epoch:  481  - cost 0.248203 - accuracy  0.915663\n",
      "epoch:  482  - cost 0.22992 - accuracy  0.927711\n",
      "epoch:  483  - cost 0.218805 - accuracy  0.933735\n",
      "epoch:  484  - cost 0.221504 - accuracy  0.915663\n",
      "epoch:  485  - cost 0.231733 - accuracy  0.89759\n",
      "epoch:  486  - cost 0.295053 - accuracy  0.879518\n",
      "epoch:  487  - cost 0.263839 - accuracy  0.86747\n",
      "epoch:  488  - cost 0.341658 - accuracy  0.843373\n",
      "epoch:  489  - cost 0.319411 - accuracy  0.837349\n",
      "epoch:  490  - cost 0.521198 - accuracy  0.728916\n",
      "epoch:  491  - cost 0.315115 - accuracy  0.873494\n",
      "epoch:  492  - cost 0.243903 - accuracy  0.909639\n",
      "epoch:  493  - cost 0.225786 - accuracy  0.915663\n",
      "epoch:  494  - cost 0.225944 - accuracy  0.909639\n",
      "epoch:  495  - cost 0.231278 - accuracy  0.903614\n",
      "epoch:  496  - cost 0.303869 - accuracy  0.86747\n",
      "epoch:  497  - cost 0.245254 - accuracy  0.903614\n",
      "epoch:  498  - cost 0.30442 - accuracy  0.849398\n",
      "epoch:  499  - cost 0.307707 - accuracy  0.861446\n",
      "epoch:  500  - cost 0.533532 - accuracy  0.728916\n",
      "epoch:  501  - cost 0.335532 - accuracy  0.855422\n",
      "epoch:  502  - cost 0.256797 - accuracy  0.891566\n",
      "epoch:  503  - cost 0.222483 - accuracy  0.909639\n",
      "epoch:  504  - cost 0.222832 - accuracy  0.909639\n",
      "epoch:  505  - cost 0.215514 - accuracy  0.909639\n",
      "epoch:  506  - cost 0.257556 - accuracy  0.885542\n",
      "epoch:  507  - cost 0.247631 - accuracy  0.909639\n",
      "epoch:  508  - cost 0.387046 - accuracy  0.795181\n",
      "epoch:  509  - cost 0.299709 - accuracy  0.849398\n",
      "epoch:  510  - cost 0.38165 - accuracy  0.813253\n",
      "epoch:  511  - cost 0.255301 - accuracy  0.903614\n",
      "epoch:  512  - cost 0.288596 - accuracy  0.879518\n",
      "epoch:  513  - cost 0.21779 - accuracy  0.915663\n",
      "epoch:  514  - cost 0.215723 - accuracy  0.903614\n",
      "epoch:  515  - cost 0.208289 - accuracy  0.915663\n",
      "epoch:  516  - cost 0.261703 - accuracy  0.885542\n",
      "epoch:  517  - cost 0.282137 - accuracy  0.861446\n",
      "epoch:  518  - cost 0.551378 - accuracy  0.722892\n",
      "epoch:  519  - cost 0.389229 - accuracy  0.837349\n",
      "epoch:  520  - cost 0.364966 - accuracy  0.801205\n",
      "epoch:  521  - cost 0.243704 - accuracy  0.921687\n",
      "epoch:  522  - cost 0.23282 - accuracy  0.915663\n",
      "epoch:  523  - cost 0.201293 - accuracy  0.933735\n",
      "epoch:  524  - cost 0.198253 - accuracy  0.921687\n",
      "epoch:  525  - cost 0.195766 - accuracy  0.927711\n",
      "epoch:  526  - cost 0.220565 - accuracy  0.909639\n",
      "epoch:  527  - cost 0.23133 - accuracy  0.909639\n",
      "epoch:  528  - cost 0.377231 - accuracy  0.807229\n",
      "epoch:  529  - cost 0.282103 - accuracy  0.873494\n",
      "epoch:  530  - cost 0.348858 - accuracy  0.831325\n",
      "epoch:  531  - cost 0.272615 - accuracy  0.873494\n",
      "epoch:  532  - cost 0.366484 - accuracy  0.807229\n",
      "epoch:  533  - cost 0.238285 - accuracy  0.915663\n",
      "epoch:  534  - cost 0.194211 - accuracy  0.921687\n",
      "epoch:  535  - cost 0.187495 - accuracy  0.927711\n",
      "epoch:  536  - cost 0.19633 - accuracy  0.909639\n",
      "epoch:  537  - cost 0.192383 - accuracy  0.927711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  538  - cost 0.238986 - accuracy  0.891566\n",
      "epoch:  539  - cost 0.288829 - accuracy  0.861446\n",
      "epoch:  540  - cost 0.655904 - accuracy  0.722892\n",
      "epoch:  541  - cost 0.501631 - accuracy  0.740964\n",
      "epoch:  542  - cost 0.431067 - accuracy  0.76506\n",
      "epoch:  543  - cost 0.30272 - accuracy  0.849398\n",
      "epoch:  544  - cost 0.288949 - accuracy  0.86747\n",
      "epoch:  545  - cost 0.251747 - accuracy  0.903614\n",
      "epoch:  546  - cost 0.258303 - accuracy  0.891566\n",
      "epoch:  547  - cost 0.207331 - accuracy  0.933735\n",
      "epoch:  548  - cost 0.21256 - accuracy  0.909639\n",
      "epoch:  549  - cost 0.209835 - accuracy  0.921687\n",
      "epoch:  550  - cost 0.251542 - accuracy  0.89759\n",
      "epoch:  551  - cost 0.230378 - accuracy  0.909639\n",
      "epoch:  552  - cost 0.355387 - accuracy  0.825301\n",
      "epoch:  553  - cost 0.277288 - accuracy  0.879518\n",
      "epoch:  554  - cost 0.350135 - accuracy  0.825301\n",
      "epoch:  555  - cost 0.238426 - accuracy  0.903614\n",
      "epoch:  556  - cost 0.283503 - accuracy  0.885542\n",
      "epoch:  557  - cost 0.194493 - accuracy  0.927711\n",
      "epoch:  558  - cost 0.186344 - accuracy  0.921687\n",
      "epoch:  559  - cost 0.17788 - accuracy  0.939759\n",
      "epoch:  560  - cost 0.187653 - accuracy  0.915663\n",
      "epoch:  561  - cost 0.188492 - accuracy  0.921687\n",
      "epoch:  562  - cost 0.269811 - accuracy  0.885542\n",
      "epoch:  563  - cost 0.299013 - accuracy  0.861446\n",
      "epoch:  564  - cost 0.736449 - accuracy  0.674699\n",
      "epoch:  565  - cost 0.517341 - accuracy  0.73494\n",
      "epoch:  566  - cost 0.426169 - accuracy  0.76506\n",
      "epoch:  567  - cost 0.274835 - accuracy  0.89759\n",
      "epoch:  568  - cost 0.240231 - accuracy  0.879518\n",
      "epoch:  569  - cost 0.215182 - accuracy  0.927711\n",
      "epoch:  570  - cost 0.201772 - accuracy  0.927711\n",
      "epoch:  571  - cost 0.191248 - accuracy  0.927711\n",
      "epoch:  572  - cost 0.199255 - accuracy  0.921687\n",
      "epoch:  573  - cost 0.192201 - accuracy  0.927711\n",
      "epoch:  574  - cost 0.256369 - accuracy  0.903614\n",
      "epoch:  575  - cost 0.211941 - accuracy  0.921687\n",
      "epoch:  576  - cost 0.305103 - accuracy  0.86747\n",
      "epoch:  577  - cost 0.2257 - accuracy  0.909639\n",
      "epoch:  578  - cost 0.281422 - accuracy  0.86747\n",
      "epoch:  579  - cost 0.227944 - accuracy  0.915663\n",
      "epoch:  580  - cost 0.356438 - accuracy  0.813253\n",
      "epoch:  581  - cost 0.220373 - accuracy  0.909639\n",
      "epoch:  582  - cost 0.201737 - accuracy  0.915663\n",
      "epoch:  583  - cost 0.186533 - accuracy  0.921687\n",
      "epoch:  584  - cost 0.233342 - accuracy  0.903614\n",
      "epoch:  585  - cost 0.179617 - accuracy  0.933735\n",
      "epoch:  586  - cost 0.20168 - accuracy  0.909639\n",
      "epoch:  587  - cost 0.194781 - accuracy  0.927711\n",
      "epoch:  588  - cost 0.285554 - accuracy  0.885542\n",
      "epoch:  589  - cost 0.230455 - accuracy  0.915663\n",
      "epoch:  590  - cost 0.303937 - accuracy  0.849398\n",
      "epoch:  591  - cost 0.32394 - accuracy  0.831325\n",
      "epoch:  592  - cost 0.634468 - accuracy  0.716867\n",
      "epoch:  593  - cost 0.566443 - accuracy  0.668675\n",
      "epoch:  594  - cost 0.351774 - accuracy  0.825301\n",
      "epoch:  595  - cost 0.265549 - accuracy  0.89759\n",
      "epoch:  596  - cost 0.34021 - accuracy  0.819277\n",
      "epoch:  597  - cost 0.237192 - accuracy  0.89759\n",
      "epoch:  598  - cost 0.254542 - accuracy  0.885542\n",
      "epoch:  599  - cost 0.229444 - accuracy  0.903614\n",
      "epoch:  600  - cost 0.261713 - accuracy  0.885542\n",
      "epoch:  601  - cost 0.235091 - accuracy  0.903614\n",
      "epoch:  602  - cost 0.320641 - accuracy  0.849398\n",
      "epoch:  603  - cost 0.258734 - accuracy  0.885542\n",
      "epoch:  604  - cost 0.407413 - accuracy  0.795181\n",
      "epoch:  605  - cost 0.22375 - accuracy  0.915663\n",
      "epoch:  606  - cost 0.228032 - accuracy  0.909639\n",
      "epoch:  607  - cost 0.176722 - accuracy  0.939759\n",
      "epoch:  608  - cost 0.174682 - accuracy  0.927711\n",
      "epoch:  609  - cost 0.160989 - accuracy  0.951807\n",
      "epoch:  610  - cost 0.168927 - accuracy  0.915663\n",
      "epoch:  611  - cost 0.168312 - accuracy  0.939759\n",
      "epoch:  612  - cost 0.237627 - accuracy  0.903614\n",
      "epoch:  613  - cost 0.231346 - accuracy  0.89759\n",
      "epoch:  614  - cost 0.458626 - accuracy  0.753012\n",
      "epoch:  615  - cost 0.284131 - accuracy  0.885542\n",
      "epoch:  616  - cost 0.220061 - accuracy  0.903614\n",
      "epoch:  617  - cost 0.184326 - accuracy  0.933735\n",
      "epoch:  618  - cost 0.197319 - accuracy  0.921687\n",
      "epoch:  619  - cost 0.15408 - accuracy  0.957831\n",
      "epoch:  620  - cost 0.161222 - accuracy  0.921687\n",
      "epoch:  621  - cost 0.158696 - accuracy  0.939759\n",
      "epoch:  622  - cost 0.204018 - accuracy  0.915663\n",
      "epoch:  623  - cost 0.214053 - accuracy  0.903614\n",
      "epoch:  624  - cost 0.41563 - accuracy  0.771084\n",
      "epoch:  625  - cost 0.318387 - accuracy  0.855422\n",
      "epoch:  626  - cost 0.418429 - accuracy  0.771084\n",
      "epoch:  627  - cost 0.213604 - accuracy  0.927711\n",
      "epoch:  628  - cost 0.223227 - accuracy  0.915663\n",
      "epoch:  629  - cost 0.158328 - accuracy  0.951807\n",
      "epoch:  630  - cost 0.14574 - accuracy  0.945783\n",
      "epoch:  631  - cost 0.138352 - accuracy  0.96988\n",
      "epoch:  632  - cost 0.138649 - accuracy  0.945783\n",
      "epoch:  633  - cost 0.145214 - accuracy  0.951807\n",
      "epoch:  634  - cost 0.200301 - accuracy  0.921687\n",
      "epoch:  635  - cost 0.204884 - accuracy  0.921687\n",
      "epoch:  636  - cost 0.410884 - accuracy  0.783133\n",
      "epoch:  637  - cost 0.366825 - accuracy  0.819277\n",
      "epoch:  638  - cost 0.732783 - accuracy  0.638554\n",
      "epoch:  639  - cost 0.35078 - accuracy  0.837349\n",
      "epoch:  640  - cost 0.260207 - accuracy  0.927711\n",
      "epoch:  641  - cost 0.202158 - accuracy  0.957831\n",
      "epoch:  642  - cost 0.177557 - accuracy  0.945783\n",
      "epoch:  643  - cost 0.159584 - accuracy  0.963855\n",
      "epoch:  644  - cost 0.14767 - accuracy  0.945783\n",
      "epoch:  645  - cost 0.139138 - accuracy  0.96988\n",
      "epoch:  646  - cost 0.13378 - accuracy  0.951807\n",
      "epoch:  647  - cost 0.132626 - accuracy  0.96988\n",
      "epoch:  648  - cost 0.14706 - accuracy  0.927711\n",
      "epoch:  649  - cost 0.190866 - accuracy  0.909639\n",
      "epoch:  650  - cost 0.367336 - accuracy  0.831325\n",
      "epoch:  651  - cost 0.249495 - accuracy  0.885542\n",
      "epoch:  652  - cost 0.234077 - accuracy  0.879518\n",
      "epoch:  653  - cost 0.227246 - accuracy  0.891566\n",
      "epoch:  654  - cost 0.337477 - accuracy  0.837349\n",
      "epoch:  655  - cost 0.192239 - accuracy  0.909639\n",
      "epoch:  656  - cost 0.150876 - accuracy  0.945783\n",
      "epoch:  657  - cost 0.143977 - accuracy  0.945783\n",
      "epoch:  658  - cost 0.172379 - accuracy  0.921687\n",
      "epoch:  659  - cost 0.157072 - accuracy  0.957831\n",
      "epoch:  660  - cost 0.234123 - accuracy  0.909639\n",
      "epoch:  661  - cost 0.20183 - accuracy  0.933735\n",
      "epoch:  662  - cost 0.363753 - accuracy  0.825301\n",
      "epoch:  663  - cost 0.241741 - accuracy  0.89759\n",
      "epoch:  664  - cost 0.33229 - accuracy  0.843373\n",
      "epoch:  665  - cost 0.159799 - accuracy  0.957831\n",
      "epoch:  666  - cost 0.128371 - accuracy  0.963855\n",
      "epoch:  667  - cost 0.115195 - accuracy  0.975904\n",
      "epoch:  668  - cost 0.111028 - accuracy  0.963855\n",
      "epoch:  669  - cost 0.110154 - accuracy  0.96988\n",
      "epoch:  670  - cost 0.110127 - accuracy  0.957831\n",
      "epoch:  671  - cost 0.116518 - accuracy  0.96988\n",
      "epoch:  672  - cost 0.160841 - accuracy  0.927711\n",
      "epoch:  673  - cost 0.213418 - accuracy  0.903614\n",
      "epoch:  674  - cost 0.537983 - accuracy  0.73494\n",
      "epoch:  675  - cost 0.554461 - accuracy  0.722892\n",
      "epoch:  676  - cost 0.659863 - accuracy  0.698795\n",
      "epoch:  677  - cost 0.51419 - accuracy  0.692771\n",
      "epoch:  678  - cost 0.521255 - accuracy  0.704819\n",
      "epoch:  679  - cost 0.262444 - accuracy  0.879518\n",
      "epoch:  680  - cost 0.220062 - accuracy  0.909639\n",
      "epoch:  681  - cost 0.215676 - accuracy  0.903614\n",
      "epoch:  682  - cost 0.211163 - accuracy  0.885542\n",
      "epoch:  683  - cost 0.248381 - accuracy  0.879518\n",
      "epoch:  684  - cost 0.210133 - accuracy  0.903614\n",
      "epoch:  685  - cost 0.293279 - accuracy  0.855422\n",
      "epoch:  686  - cost 0.227901 - accuracy  0.89759\n",
      "epoch:  687  - cost 0.304091 - accuracy  0.843373\n",
      "epoch:  688  - cost 0.206806 - accuracy  0.915663\n",
      "epoch:  689  - cost 0.235793 - accuracy  0.891566\n",
      "epoch:  690  - cost 0.145252 - accuracy  0.96988\n",
      "epoch:  691  - cost 0.136476 - accuracy  0.939759\n",
      "epoch:  692  - cost 0.125905 - accuracy  0.96988\n",
      "epoch:  693  - cost 0.135485 - accuracy  0.933735\n",
      "epoch:  694  - cost 0.137745 - accuracy  0.957831\n",
      "epoch:  695  - cost 0.194207 - accuracy  0.921687\n",
      "epoch:  696  - cost 0.144954 - accuracy  0.957831\n",
      "epoch:  697  - cost 0.187115 - accuracy  0.921687\n",
      "epoch:  698  - cost 0.150552 - accuracy  0.957831\n",
      "epoch:  699  - cost 0.195179 - accuracy  0.915663\n",
      "epoch:  700  - cost 0.150191 - accuracy  0.951807\n",
      "epoch:  701  - cost 0.183677 - accuracy  0.927711\n",
      "epoch:  702  - cost 0.135422 - accuracy  0.963855\n",
      "epoch:  703  - cost 0.162072 - accuracy  0.927711\n",
      "epoch:  704  - cost 0.124701 - accuracy  0.963855\n",
      "epoch:  705  - cost 0.154397 - accuracy  0.927711\n",
      "epoch:  706  - cost 0.111957 - accuracy  0.96988\n",
      "epoch:  707  - cost 0.122582 - accuracy  0.939759\n",
      "epoch:  708  - cost 0.133231 - accuracy  0.945783\n",
      "epoch:  709  - cost 0.219782 - accuracy  0.903614\n",
      "epoch:  710  - cost 0.231014 - accuracy  0.909639\n",
      "epoch:  711  - cost 0.795547 - accuracy  0.692771\n",
      "epoch:  712  - cost 0.994019 - accuracy  0.644578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  713  - cost 0.860225 - accuracy  0.626506\n",
      "epoch:  714  - cost 0.332958 - accuracy  0.86747\n",
      "epoch:  715  - cost 0.300276 - accuracy  0.855422\n",
      "epoch:  716  - cost 0.277297 - accuracy  0.873494\n",
      "epoch:  717  - cost 0.261598 - accuracy  0.909639\n",
      "epoch:  718  - cost 0.258835 - accuracy  0.903614\n",
      "epoch:  719  - cost 0.265423 - accuracy  0.86747\n",
      "epoch:  720  - cost 0.300468 - accuracy  0.849398\n",
      "epoch:  721  - cost 0.201941 - accuracy  0.957831\n",
      "epoch:  722  - cost 0.182873 - accuracy  0.957831\n",
      "epoch:  723  - cost 0.163793 - accuracy  0.96988\n",
      "epoch:  724  - cost 0.155623 - accuracy  0.96988\n",
      "epoch:  725  - cost 0.149481 - accuracy  0.96988\n",
      "epoch:  726  - cost 0.157216 - accuracy  0.951807\n",
      "epoch:  727  - cost 0.14839 - accuracy  0.963855\n",
      "epoch:  728  - cost 0.185223 - accuracy  0.933735\n",
      "epoch:  729  - cost 0.156866 - accuracy  0.951807\n",
      "epoch:  730  - cost 0.206835 - accuracy  0.921687\n",
      "epoch:  731  - cost 0.173219 - accuracy  0.933735\n",
      "epoch:  732  - cost 0.274923 - accuracy  0.879518\n",
      "epoch:  733  - cost 0.144299 - accuracy  0.957831\n",
      "epoch:  734  - cost 0.116343 - accuracy  0.957831\n",
      "epoch:  735  - cost 0.113929 - accuracy  0.957831\n",
      "epoch:  736  - cost 0.15197 - accuracy  0.927711\n",
      "epoch:  737  - cost 0.181869 - accuracy  0.915663\n",
      "epoch:  738  - cost 0.401672 - accuracy  0.825301\n",
      "epoch:  739  - cost 0.28535 - accuracy  0.873494\n",
      "epoch:  740  - cost 0.314171 - accuracy  0.825301\n",
      "epoch:  741  - cost 0.310927 - accuracy  0.837349\n",
      "epoch:  742  - cost 0.519288 - accuracy  0.771084\n",
      "epoch:  743  - cost 0.320487 - accuracy  0.855422\n",
      "epoch:  744  - cost 0.160394 - accuracy  0.951807\n",
      "epoch:  745  - cost 0.130195 - accuracy  0.957831\n",
      "epoch:  746  - cost 0.127226 - accuracy  0.951807\n",
      "epoch:  747  - cost 0.111316 - accuracy  0.963855\n",
      "epoch:  748  - cost 0.125519 - accuracy  0.945783\n",
      "epoch:  749  - cost 0.119535 - accuracy  0.951807\n",
      "epoch:  750  - cost 0.176315 - accuracy  0.927711\n",
      "epoch:  751  - cost 0.12467 - accuracy  0.957831\n",
      "epoch:  752  - cost 0.182353 - accuracy  0.927711\n",
      "epoch:  753  - cost 0.117514 - accuracy  0.957831\n",
      "epoch:  754  - cost 0.153619 - accuracy  0.927711\n",
      "epoch:  755  - cost 0.131899 - accuracy  0.951807\n",
      "epoch:  756  - cost 0.217703 - accuracy  0.909639\n",
      "epoch:  757  - cost 0.140718 - accuracy  0.951807\n",
      "epoch:  758  - cost 0.198818 - accuracy  0.915663\n",
      "epoch:  759  - cost 0.163316 - accuracy  0.933735\n",
      "epoch:  760  - cost 0.30234 - accuracy  0.879518\n",
      "epoch:  761  - cost 0.184515 - accuracy  0.927711\n",
      "epoch:  762  - cost 0.183638 - accuracy  0.921687\n",
      "epoch:  763  - cost 0.142647 - accuracy  0.945783\n",
      "epoch:  764  - cost 0.201784 - accuracy  0.921687\n",
      "epoch:  765  - cost 0.105291 - accuracy  0.981928\n",
      "epoch:  766  - cost 0.0935514 - accuracy  0.96988\n",
      "epoch:  767  - cost 0.0847428 - accuracy  0.987952\n",
      "epoch:  768  - cost 0.0888597 - accuracy  0.96988\n",
      "epoch:  769  - cost 0.0859157 - accuracy  0.96988\n",
      "epoch:  770  - cost 0.0981594 - accuracy  0.957831\n",
      "epoch:  771  - cost 0.106684 - accuracy  0.963855\n",
      "epoch:  772  - cost 0.179903 - accuracy  0.921687\n",
      "epoch:  773  - cost 0.172176 - accuracy  0.927711\n",
      "epoch:  774  - cost 0.339235 - accuracy  0.843373\n",
      "epoch:  775  - cost 0.277289 - accuracy  0.879518\n",
      "epoch:  776  - cost 0.498455 - accuracy  0.76506\n",
      "epoch:  777  - cost 0.332336 - accuracy  0.837349\n",
      "epoch:  778  - cost 0.356266 - accuracy  0.813253\n",
      "epoch:  779  - cost 0.185833 - accuracy  0.921687\n",
      "epoch:  780  - cost 0.110432 - accuracy  0.957831\n",
      "epoch:  781  - cost 0.0918396 - accuracy  0.981928\n",
      "epoch:  782  - cost 0.0808094 - accuracy  0.981928\n",
      "epoch:  783  - cost 0.07585 - accuracy  0.987952\n",
      "epoch:  784  - cost 0.0726691 - accuracy  0.987952\n",
      "epoch:  785  - cost 0.0702641 - accuracy  0.987952\n",
      "epoch:  786  - cost 0.0677949 - accuracy  0.987952\n",
      "epoch:  787  - cost 0.0653248 - accuracy  0.987952\n",
      "epoch:  788  - cost 0.0653306 - accuracy  0.987952\n",
      "epoch:  789  - cost 0.0643701 - accuracy  0.993976\n",
      "epoch:  790  - cost 0.0655443 - accuracy  0.987952\n",
      "epoch:  791  - cost 0.0652266 - accuracy  0.987952\n",
      "epoch:  792  - cost 0.0692841 - accuracy  0.987952\n",
      "epoch:  793  - cost 0.0698963 - accuracy  0.975904\n",
      "epoch:  794  - cost 0.0826235 - accuracy  0.96988\n",
      "epoch:  795  - cost 0.0858649 - accuracy  0.963855\n",
      "epoch:  796  - cost 0.125715 - accuracy  0.939759\n",
      "epoch:  797  - cost 0.180716 - accuracy  0.921687\n",
      "epoch:  798  - cost 0.4487 - accuracy  0.807229\n",
      "epoch:  799  - cost 0.424349 - accuracy  0.795181\n",
      "epoch:  800  - cost 0.50982 - accuracy  0.795181\n",
      "epoch:  801  - cost 0.776913 - accuracy  0.63253\n",
      "epoch:  802  - cost 1.02506 - accuracy  0.60241\n",
      "epoch:  803  - cost 0.336364 - accuracy  0.879518\n",
      "epoch:  804  - cost 0.264384 - accuracy  0.927711\n",
      "epoch:  805  - cost 0.238414 - accuracy  0.927711\n",
      "epoch:  806  - cost 0.174357 - accuracy  0.96988\n",
      "epoch:  807  - cost 0.153214 - accuracy  0.951807\n",
      "epoch:  808  - cost 0.129563 - accuracy  0.981928\n",
      "epoch:  809  - cost 0.116702 - accuracy  0.981928\n",
      "epoch:  810  - cost 0.105678 - accuracy  0.975904\n",
      "epoch:  811  - cost 0.0988115 - accuracy  0.987952\n",
      "epoch:  812  - cost 0.0917333 - accuracy  0.981928\n",
      "epoch:  813  - cost 0.089266 - accuracy  0.981928\n",
      "epoch:  814  - cost 0.084264 - accuracy  0.981928\n",
      "epoch:  815  - cost 0.0910793 - accuracy  0.96988\n",
      "epoch:  816  - cost 0.0958011 - accuracy  0.975904\n",
      "epoch:  817  - cost 0.142317 - accuracy  0.939759\n",
      "epoch:  818  - cost 0.13453 - accuracy  0.951807\n",
      "epoch:  819  - cost 0.240089 - accuracy  0.885542\n",
      "epoch:  820  - cost 0.138517 - accuracy  0.951807\n",
      "epoch:  821  - cost 0.154348 - accuracy  0.933735\n",
      "epoch:  822  - cost 0.103844 - accuracy  0.963855\n",
      "epoch:  823  - cost 0.109088 - accuracy  0.951807\n",
      "epoch:  824  - cost 0.0803619 - accuracy  0.981928\n",
      "epoch:  825  - cost 0.088067 - accuracy  0.963855\n",
      "epoch:  826  - cost 0.0720007 - accuracy  0.987952\n",
      "epoch:  827  - cost 0.081673 - accuracy  0.96988\n",
      "epoch:  828  - cost 0.0708316 - accuracy  0.987952\n",
      "epoch:  829  - cost 0.0788024 - accuracy  0.96988\n",
      "epoch:  830  - cost 0.0665521 - accuracy  0.987952\n",
      "epoch:  831  - cost 0.0696552 - accuracy  0.987952\n",
      "epoch:  832  - cost 0.0575189 - accuracy  0.993976\n",
      "epoch:  833  - cost 0.0571122 - accuracy  0.987952\n",
      "epoch:  834  - cost 0.0507034 - accuracy  1.0\n",
      "epoch:  835  - cost 0.0499033 - accuracy  0.987952\n",
      "epoch:  836  - cost 0.0459445 - accuracy  1.0\n",
      "epoch:  837  - cost 0.0439151 - accuracy  0.993976\n",
      "epoch:  838  - cost 0.0416437 - accuracy  1.0\n",
      "epoch:  839  - cost 0.0402032 - accuracy  0.993976\n",
      "epoch:  840  - cost 0.0390187 - accuracy  0.993976\n",
      "epoch:  841  - cost 0.0381799 - accuracy  0.993976\n",
      "epoch:  842  - cost 0.0373333 - accuracy  0.993976\n",
      "epoch:  843  - cost 0.0367123 - accuracy  0.993976\n",
      "epoch:  844  - cost 0.0359435 - accuracy  0.993976\n",
      "epoch:  845  - cost 0.0353347 - accuracy  0.993976\n",
      "epoch:  846  - cost 0.0347967 - accuracy  1.0\n",
      "epoch:  847  - cost 0.0342253 - accuracy  0.993976\n",
      "epoch:  848  - cost 0.0337806 - accuracy  1.0\n",
      "epoch:  849  - cost 0.0334696 - accuracy  0.993976\n",
      "epoch:  850  - cost 0.0332187 - accuracy  1.0\n",
      "epoch:  851  - cost 0.0336965 - accuracy  0.993976\n",
      "epoch:  852  - cost 0.0335263 - accuracy  1.0\n",
      "epoch:  853  - cost 0.034482 - accuracy  0.993976\n",
      "epoch:  854  - cost 0.0328023 - accuracy  1.0\n",
      "epoch:  855  - cost 0.0336681 - accuracy  0.993976\n",
      "epoch:  856  - cost 0.0319978 - accuracy  1.0\n",
      "epoch:  857  - cost 0.0323791 - accuracy  0.993976\n",
      "epoch:  858  - cost 0.0309953 - accuracy  1.0\n",
      "epoch:  859  - cost 0.0311141 - accuracy  0.993976\n",
      "epoch:  860  - cost 0.0301757 - accuracy  1.0\n",
      "epoch:  861  - cost 0.0305701 - accuracy  0.993976\n",
      "epoch:  862  - cost 0.0295951 - accuracy  1.0\n",
      "epoch:  863  - cost 0.0296533 - accuracy  0.993976\n",
      "epoch:  864  - cost 0.028473 - accuracy  1.0\n",
      "epoch:  865  - cost 0.0284692 - accuracy  1.0\n",
      "epoch:  866  - cost 0.0275049 - accuracy  1.0\n",
      "epoch:  867  - cost 0.0278364 - accuracy  1.0\n",
      "epoch:  868  - cost 0.026863 - accuracy  1.0\n",
      "epoch:  869  - cost 0.0272629 - accuracy  1.0\n",
      "epoch:  870  - cost 0.0265845 - accuracy  1.0\n",
      "epoch:  871  - cost 0.0270514 - accuracy  1.0\n",
      "epoch:  872  - cost 0.0264921 - accuracy  1.0\n",
      "epoch:  873  - cost 0.0275546 - accuracy  1.0\n",
      "epoch:  874  - cost 0.026777 - accuracy  1.0\n",
      "epoch:  875  - cost 0.0291043 - accuracy  0.993976\n",
      "epoch:  876  - cost 0.0278582 - accuracy  1.0\n",
      "epoch:  877  - cost 0.0295625 - accuracy  0.993976\n",
      "epoch:  878  - cost 0.0278957 - accuracy  1.0\n",
      "epoch:  879  - cost 0.0299735 - accuracy  0.993976\n",
      "epoch:  880  - cost 0.028134 - accuracy  1.0\n",
      "epoch:  881  - cost 0.0296235 - accuracy  0.993976\n",
      "epoch:  882  - cost 0.027501 - accuracy  1.0\n",
      "epoch:  883  - cost 0.0295066 - accuracy  0.993976\n",
      "epoch:  884  - cost 0.027126 - accuracy  1.0\n",
      "epoch:  885  - cost 0.0275625 - accuracy  0.993976\n",
      "epoch:  886  - cost 0.0246892 - accuracy  1.0\n",
      "epoch:  887  - cost 0.0242206 - accuracy  1.0\n",
      "epoch:  888  - cost 0.0222492 - accuracy  1.0\n",
      "epoch:  889  - cost 0.0215785 - accuracy  1.0\n",
      "epoch:  890  - cost 0.0206051 - accuracy  1.0\n",
      "epoch:  891  - cost 0.0200079 - accuracy  1.0\n",
      "epoch:  892  - cost 0.0197267 - accuracy  1.0\n",
      "epoch:  893  - cost 0.0194451 - accuracy  1.0\n",
      "epoch:  894  - cost 0.0192102 - accuracy  1.0\n",
      "epoch:  895  - cost 0.0189878 - accuracy  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  896  - cost 0.0188062 - accuracy  1.0\n",
      "epoch:  897  - cost 0.0186295 - accuracy  1.0\n",
      "epoch:  898  - cost 0.018482 - accuracy  1.0\n",
      "epoch:  899  - cost 0.0183594 - accuracy  1.0\n",
      "epoch:  900  - cost 0.0181598 - accuracy  1.0\n",
      "epoch:  901  - cost 0.0181776 - accuracy  1.0\n",
      "epoch:  902  - cost 0.0179808 - accuracy  1.0\n",
      "epoch:  903  - cost 0.017799 - accuracy  1.0\n",
      "epoch:  904  - cost 0.0175582 - accuracy  1.0\n",
      "epoch:  905  - cost 0.0174682 - accuracy  1.0\n",
      "epoch:  906  - cost 0.0172129 - accuracy  1.0\n",
      "epoch:  907  - cost 0.0170629 - accuracy  1.0\n",
      "epoch:  908  - cost 0.0168689 - accuracy  1.0\n",
      "epoch:  909  - cost 0.0167833 - accuracy  1.0\n",
      "epoch:  910  - cost 0.016565 - accuracy  1.0\n",
      "epoch:  911  - cost 0.016428 - accuracy  1.0\n",
      "epoch:  912  - cost 0.0162867 - accuracy  1.0\n",
      "epoch:  913  - cost 0.016271 - accuracy  1.0\n",
      "epoch:  914  - cost 0.0160414 - accuracy  1.0\n",
      "epoch:  915  - cost 0.0159335 - accuracy  1.0\n",
      "epoch:  916  - cost 0.0157896 - accuracy  1.0\n",
      "epoch:  917  - cost 0.0156873 - accuracy  1.0\n",
      "epoch:  918  - cost 0.0154979 - accuracy  1.0\n",
      "epoch:  919  - cost 0.0153763 - accuracy  1.0\n",
      "epoch:  920  - cost 0.0151939 - accuracy  1.0\n",
      "epoch:  921  - cost 0.0150505 - accuracy  1.0\n",
      "epoch:  922  - cost 0.0148999 - accuracy  1.0\n",
      "epoch:  923  - cost 0.0148163 - accuracy  1.0\n",
      "epoch:  924  - cost 0.0146694 - accuracy  1.0\n",
      "epoch:  925  - cost 0.0145512 - accuracy  1.0\n",
      "epoch:  926  - cost 0.014449 - accuracy  1.0\n",
      "epoch:  927  - cost 0.0143938 - accuracy  1.0\n",
      "epoch:  928  - cost 0.0142192 - accuracy  1.0\n",
      "epoch:  929  - cost 0.0140767 - accuracy  1.0\n",
      "epoch:  930  - cost 0.013986 - accuracy  1.0\n",
      "epoch:  931  - cost 0.0139193 - accuracy  1.0\n",
      "epoch:  932  - cost 0.0137567 - accuracy  1.0\n",
      "epoch:  933  - cost 0.0136554 - accuracy  1.0\n",
      "epoch:  934  - cost 0.0135556 - accuracy  1.0\n",
      "epoch:  935  - cost 0.0134992 - accuracy  1.0\n",
      "epoch:  936  - cost 0.0133768 - accuracy  1.0\n",
      "epoch:  937  - cost 0.0132146 - accuracy  1.0\n",
      "epoch:  938  - cost 0.013116 - accuracy  1.0\n",
      "epoch:  939  - cost 0.0130712 - accuracy  1.0\n",
      "epoch:  940  - cost 0.0129876 - accuracy  1.0\n",
      "epoch:  941  - cost 0.012911 - accuracy  1.0\n",
      "epoch:  942  - cost 0.0128137 - accuracy  1.0\n",
      "epoch:  943  - cost 0.0126859 - accuracy  1.0\n",
      "epoch:  944  - cost 0.0125664 - accuracy  1.0\n",
      "epoch:  945  - cost 0.0124972 - accuracy  1.0\n",
      "epoch:  946  - cost 0.0124173 - accuracy  1.0\n",
      "epoch:  947  - cost 0.0122889 - accuracy  1.0\n",
      "epoch:  948  - cost 0.0121934 - accuracy  1.0\n",
      "epoch:  949  - cost 0.0121224 - accuracy  1.0\n",
      "epoch:  950  - cost 0.0120145 - accuracy  1.0\n",
      "epoch:  951  - cost 0.0118952 - accuracy  1.0\n",
      "epoch:  952  - cost 0.0118029 - accuracy  1.0\n",
      "epoch:  953  - cost 0.0117153 - accuracy  1.0\n",
      "epoch:  954  - cost 0.011666 - accuracy  1.0\n",
      "epoch:  955  - cost 0.0115979 - accuracy  1.0\n",
      "epoch:  956  - cost 0.0114841 - accuracy  1.0\n",
      "epoch:  957  - cost 0.0114015 - accuracy  1.0\n",
      "epoch:  958  - cost 0.0113361 - accuracy  1.0\n",
      "epoch:  959  - cost 0.0113036 - accuracy  1.0\n",
      "epoch:  960  - cost 0.0111959 - accuracy  1.0\n",
      "epoch:  961  - cost 0.0111741 - accuracy  1.0\n",
      "epoch:  962  - cost 0.0110563 - accuracy  1.0\n",
      "epoch:  963  - cost 0.0109593 - accuracy  1.0\n",
      "epoch:  964  - cost 0.0108746 - accuracy  1.0\n",
      "epoch:  965  - cost 0.0108019 - accuracy  1.0\n",
      "epoch:  966  - cost 0.0107268 - accuracy  1.0\n",
      "epoch:  967  - cost 0.0106766 - accuracy  1.0\n",
      "epoch:  968  - cost 0.0106102 - accuracy  1.0\n",
      "epoch:  969  - cost 0.0105626 - accuracy  1.0\n",
      "epoch:  970  - cost 0.010488 - accuracy  1.0\n",
      "epoch:  971  - cost 0.0103943 - accuracy  1.0\n",
      "epoch:  972  - cost 0.0103207 - accuracy  1.0\n",
      "epoch:  973  - cost 0.0102826 - accuracy  1.0\n",
      "epoch:  974  - cost 0.0102013 - accuracy  1.0\n",
      "epoch:  975  - cost 0.0101277 - accuracy  1.0\n",
      "epoch:  976  - cost 0.0100519 - accuracy  1.0\n",
      "epoch:  977  - cost 0.0100109 - accuracy  1.0\n",
      "epoch:  978  - cost 0.00993468 - accuracy  1.0\n",
      "epoch:  979  - cost 0.00988158 - accuracy  1.0\n",
      "epoch:  980  - cost 0.00980651 - accuracy  1.0\n",
      "epoch:  981  - cost 0.00973336 - accuracy  1.0\n",
      "epoch:  982  - cost 0.00966241 - accuracy  1.0\n",
      "epoch:  983  - cost 0.00963012 - accuracy  1.0\n",
      "epoch:  984  - cost 0.00957232 - accuracy  1.0\n",
      "epoch:  985  - cost 0.00953153 - accuracy  1.0\n",
      "epoch:  986  - cost 0.00945323 - accuracy  1.0\n",
      "epoch:  987  - cost 0.0093829 - accuracy  1.0\n",
      "epoch:  988  - cost 0.00932017 - accuracy  1.0\n",
      "epoch:  989  - cost 0.00928263 - accuracy  1.0\n",
      "epoch:  990  - cost 0.00923216 - accuracy  1.0\n",
      "epoch:  991  - cost 0.00917697 - accuracy  1.0\n",
      "epoch:  992  - cost 0.00911167 - accuracy  1.0\n",
      "epoch:  993  - cost 0.00906147 - accuracy  1.0\n",
      "epoch:  994  - cost 0.00900999 - accuracy  1.0\n",
      "epoch:  995  - cost 0.0089704 - accuracy  1.0\n",
      "epoch:  996  - cost 0.00890515 - accuracy  1.0\n",
      "epoch:  997  - cost 0.00884281 - accuracy  1.0\n",
      "epoch:  998  - cost 0.00881035 - accuracy  1.0\n",
      "epoch:  999  - cost 0.00874424 - accuracy  1.0\n",
      "epoch:  1000  - cost 0.00869842 - accuracy  1.0\n",
      "epoch:  1001  - cost 0.00864657 - accuracy  1.0\n",
      "epoch:  1002  - cost 0.00862455 - accuracy  1.0\n",
      "epoch:  1003  - cost 0.00856587 - accuracy  1.0\n",
      "epoch:  1004  - cost 0.008525 - accuracy  1.0\n",
      "epoch:  1005  - cost 0.00847249 - accuracy  1.0\n",
      "epoch:  1006  - cost 0.00844257 - accuracy  1.0\n",
      "epoch:  1007  - cost 0.00837188 - accuracy  1.0\n",
      "epoch:  1008  - cost 0.00832156 - accuracy  1.0\n",
      "epoch:  1009  - cost 0.00828132 - accuracy  1.0\n",
      "epoch:  1010  - cost 0.00822844 - accuracy  1.0\n",
      "epoch:  1011  - cost 0.00818995 - accuracy  1.0\n",
      "epoch:  1012  - cost 0.00814048 - accuracy  1.0\n",
      "epoch:  1013  - cost 0.00812008 - accuracy  1.0\n",
      "epoch:  1014  - cost 0.00805605 - accuracy  1.0\n",
      "epoch:  1015  - cost 0.00801321 - accuracy  1.0\n",
      "epoch:  1016  - cost 0.00797357 - accuracy  1.0\n",
      "epoch:  1017  - cost 0.00792423 - accuracy  1.0\n",
      "epoch:  1018  - cost 0.00788887 - accuracy  1.0\n",
      "epoch:  1019  - cost 0.00784541 - accuracy  1.0\n",
      "epoch:  1020  - cost 0.0078185 - accuracy  1.0\n",
      "epoch:  1021  - cost 0.0077815 - accuracy  1.0\n",
      "epoch:  1022  - cost 0.00774214 - accuracy  1.0\n",
      "epoch:  1023  - cost 0.00771972 - accuracy  1.0\n",
      "epoch:  1024  - cost 0.00765331 - accuracy  1.0\n",
      "epoch:  1025  - cost 0.00761415 - accuracy  1.0\n",
      "epoch:  1026  - cost 0.00756599 - accuracy  1.0\n",
      "epoch:  1027  - cost 0.0075246 - accuracy  1.0\n",
      "epoch:  1028  - cost 0.00749374 - accuracy  1.0\n",
      "epoch:  1029  - cost 0.00745012 - accuracy  1.0\n",
      "epoch:  1030  - cost 0.00741987 - accuracy  1.0\n",
      "epoch:  1031  - cost 0.00739636 - accuracy  1.0\n",
      "epoch:  1032  - cost 0.00735289 - accuracy  1.0\n",
      "epoch:  1033  - cost 0.00732567 - accuracy  1.0\n",
      "epoch:  1034  - cost 0.00728715 - accuracy  1.0\n",
      "epoch:  1035  - cost 0.00726588 - accuracy  1.0\n",
      "epoch:  1036  - cost 0.00720321 - accuracy  1.0\n",
      "epoch:  1037  - cost 0.00717638 - accuracy  1.0\n",
      "epoch:  1038  - cost 0.00713581 - accuracy  1.0\n",
      "epoch:  1039  - cost 0.00710084 - accuracy  1.0\n",
      "epoch:  1040  - cost 0.00706323 - accuracy  1.0\n",
      "epoch:  1041  - cost 0.00702093 - accuracy  1.0\n",
      "epoch:  1042  - cost 0.00697446 - accuracy  1.0\n",
      "epoch:  1043  - cost 0.00692998 - accuracy  1.0\n",
      "epoch:  1044  - cost 0.00689835 - accuracy  1.0\n",
      "epoch:  1045  - cost 0.00686037 - accuracy  1.0\n",
      "epoch:  1046  - cost 0.0068382 - accuracy  1.0\n",
      "epoch:  1047  - cost 0.00678736 - accuracy  1.0\n",
      "epoch:  1048  - cost 0.00675491 - accuracy  1.0\n",
      "epoch:  1049  - cost 0.00671858 - accuracy  1.0\n",
      "epoch:  1050  - cost 0.0066827 - accuracy  1.0\n",
      "epoch:  1051  - cost 0.00664355 - accuracy  1.0\n",
      "epoch:  1052  - cost 0.00661163 - accuracy  1.0\n",
      "epoch:  1053  - cost 0.00657578 - accuracy  1.0\n",
      "epoch:  1054  - cost 0.00655794 - accuracy  1.0\n",
      "epoch:  1055  - cost 0.0065215 - accuracy  1.0\n",
      "epoch:  1056  - cost 0.00649134 - accuracy  1.0\n",
      "epoch:  1057  - cost 0.0064467 - accuracy  1.0\n",
      "epoch:  1058  - cost 0.0064179 - accuracy  1.0\n",
      "epoch:  1059  - cost 0.0063834 - accuracy  1.0\n",
      "epoch:  1060  - cost 0.00635804 - accuracy  1.0\n",
      "epoch:  1061  - cost 0.00633246 - accuracy  1.0\n",
      "epoch:  1062  - cost 0.00629795 - accuracy  1.0\n",
      "epoch:  1063  - cost 0.00626564 - accuracy  1.0\n",
      "epoch:  1064  - cost 0.00624695 - accuracy  1.0\n",
      "epoch:  1065  - cost 0.00621303 - accuracy  1.0\n",
      "epoch:  1066  - cost 0.00618297 - accuracy  1.0\n",
      "epoch:  1067  - cost 0.00615126 - accuracy  1.0\n",
      "epoch:  1068  - cost 0.00611633 - accuracy  1.0\n",
      "epoch:  1069  - cost 0.00610009 - accuracy  1.0\n",
      "epoch:  1070  - cost 0.00606368 - accuracy  1.0\n",
      "epoch:  1071  - cost 0.00604861 - accuracy  1.0\n",
      "epoch:  1072  - cost 0.00602202 - accuracy  1.0\n",
      "epoch:  1073  - cost 0.00598903 - accuracy  1.0\n",
      "epoch:  1074  - cost 0.00595903 - accuracy  1.0\n",
      "epoch:  1075  - cost 0.0059294 - accuracy  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1076  - cost 0.00590261 - accuracy  1.0\n",
      "epoch:  1077  - cost 0.00587881 - accuracy  1.0\n",
      "epoch:  1078  - cost 0.00585286 - accuracy  1.0\n",
      "epoch:  1079  - cost 0.00583121 - accuracy  1.0\n",
      "epoch:  1080  - cost 0.00580384 - accuracy  1.0\n",
      "epoch:  1081  - cost 0.00577256 - accuracy  1.0\n",
      "epoch:  1082  - cost 0.00574921 - accuracy  1.0\n",
      "epoch:  1083  - cost 0.00572776 - accuracy  1.0\n",
      "epoch:  1084  - cost 0.00569481 - accuracy  1.0\n",
      "epoch:  1085  - cost 0.00567884 - accuracy  1.0\n",
      "epoch:  1086  - cost 0.00564533 - accuracy  1.0\n",
      "epoch:  1087  - cost 0.00563024 - accuracy  1.0\n",
      "epoch:  1088  - cost 0.00560138 - accuracy  1.0\n",
      "epoch:  1089  - cost 0.00557777 - accuracy  1.0\n",
      "epoch:  1090  - cost 0.00554948 - accuracy  1.0\n",
      "epoch:  1091  - cost 0.00552142 - accuracy  1.0\n",
      "epoch:  1092  - cost 0.00549834 - accuracy  1.0\n",
      "epoch:  1093  - cost 0.00548748 - accuracy  1.0\n",
      "epoch:  1094  - cost 0.00545527 - accuracy  1.0\n",
      "epoch:  1095  - cost 0.00542983 - accuracy  1.0\n",
      "epoch:  1096  - cost 0.0054105 - accuracy  1.0\n",
      "epoch:  1097  - cost 0.00539088 - accuracy  1.0\n",
      "epoch:  1098  - cost 0.00536084 - accuracy  1.0\n",
      "epoch:  1099  - cost 0.00533955 - accuracy  1.0\n",
      "epoch:  1100  - cost 0.00531491 - accuracy  1.0\n",
      "epoch:  1101  - cost 0.00529385 - accuracy  1.0\n",
      "epoch:  1102  - cost 0.00528212 - accuracy  1.0\n",
      "epoch:  1103  - cost 0.00525839 - accuracy  1.0\n",
      "epoch:  1104  - cost 0.00523709 - accuracy  1.0\n",
      "epoch:  1105  - cost 0.00521316 - accuracy  1.0\n",
      "epoch:  1106  - cost 0.00519206 - accuracy  1.0\n",
      "epoch:  1107  - cost 0.00517815 - accuracy  1.0\n",
      "epoch:  1108  - cost 0.00515477 - accuracy  1.0\n",
      "epoch:  1109  - cost 0.00513616 - accuracy  1.0\n",
      "epoch:  1110  - cost 0.00510905 - accuracy  1.0\n",
      "epoch:  1111  - cost 0.0050908 - accuracy  1.0\n",
      "epoch:  1112  - cost 0.00507242 - accuracy  1.0\n",
      "epoch:  1113  - cost 0.0050478 - accuracy  1.0\n",
      "epoch:  1114  - cost 0.00502609 - accuracy  1.0\n",
      "epoch:  1115  - cost 0.00501131 - accuracy  1.0\n",
      "epoch:  1116  - cost 0.0050006 - accuracy  1.0\n",
      "epoch:  1117  - cost 0.00497616 - accuracy  1.0\n",
      "epoch:  1118  - cost 0.00495502 - accuracy  1.0\n",
      "epoch:  1119  - cost 0.00493941 - accuracy  1.0\n",
      "epoch:  1120  - cost 0.00491612 - accuracy  1.0\n",
      "epoch:  1121  - cost 0.00489869 - accuracy  1.0\n",
      "epoch:  1122  - cost 0.0048726 - accuracy  1.0\n",
      "epoch:  1123  - cost 0.0048554 - accuracy  1.0\n",
      "epoch:  1124  - cost 0.00483334 - accuracy  1.0\n",
      "epoch:  1125  - cost 0.00481834 - accuracy  1.0\n",
      "epoch:  1126  - cost 0.00480192 - accuracy  1.0\n",
      "epoch:  1127  - cost 0.00478953 - accuracy  1.0\n",
      "epoch:  1128  - cost 0.00476869 - accuracy  1.0\n",
      "epoch:  1129  - cost 0.00474986 - accuracy  1.0\n",
      "epoch:  1130  - cost 0.00473015 - accuracy  1.0\n",
      "epoch:  1131  - cost 0.00470831 - accuracy  1.0\n",
      "epoch:  1132  - cost 0.00469285 - accuracy  1.0\n",
      "epoch:  1133  - cost 0.00468035 - accuracy  1.0\n",
      "epoch:  1134  - cost 0.00465807 - accuracy  1.0\n",
      "epoch:  1135  - cost 0.00464152 - accuracy  1.0\n",
      "epoch:  1136  - cost 0.00461639 - accuracy  1.0\n",
      "epoch:  1137  - cost 0.00459778 - accuracy  1.0\n",
      "epoch:  1138  - cost 0.00458626 - accuracy  1.0\n",
      "epoch:  1139  - cost 0.00457011 - accuracy  1.0\n",
      "epoch:  1140  - cost 0.00454991 - accuracy  1.0\n",
      "epoch:  1141  - cost 0.00453792 - accuracy  1.0\n",
      "epoch:  1142  - cost 0.00452042 - accuracy  1.0\n",
      "epoch:  1143  - cost 0.00449971 - accuracy  1.0\n",
      "epoch:  1144  - cost 0.00447807 - accuracy  1.0\n",
      "epoch:  1145  - cost 0.00446322 - accuracy  1.0\n",
      "epoch:  1146  - cost 0.00444755 - accuracy  1.0\n",
      "epoch:  1147  - cost 0.00443202 - accuracy  1.0\n",
      "epoch:  1148  - cost 0.0044238 - accuracy  1.0\n",
      "epoch:  1149  - cost 0.00440017 - accuracy  1.0\n",
      "epoch:  1150  - cost 0.00438745 - accuracy  1.0\n",
      "epoch:  1151  - cost 0.00436466 - accuracy  1.0\n",
      "epoch:  1152  - cost 0.00435128 - accuracy  1.0\n",
      "epoch:  1153  - cost 0.00433073 - accuracy  1.0\n",
      "epoch:  1154  - cost 0.00432495 - accuracy  1.0\n",
      "epoch:  1155  - cost 0.00429899 - accuracy  1.0\n",
      "epoch:  1156  - cost 0.00429321 - accuracy  1.0\n",
      "epoch:  1157  - cost 0.00426435 - accuracy  1.0\n",
      "epoch:  1158  - cost 0.00425213 - accuracy  1.0\n",
      "epoch:  1159  - cost 0.00423677 - accuracy  1.0\n",
      "epoch:  1160  - cost 0.00422215 - accuracy  1.0\n",
      "epoch:  1161  - cost 0.00420823 - accuracy  1.0\n",
      "epoch:  1162  - cost 0.00419655 - accuracy  1.0\n",
      "epoch:  1163  - cost 0.00417668 - accuracy  1.0\n",
      "epoch:  1164  - cost 0.00416336 - accuracy  1.0\n",
      "epoch:  1165  - cost 0.00414527 - accuracy  1.0\n",
      "epoch:  1166  - cost 0.00413258 - accuracy  1.0\n",
      "epoch:  1167  - cost 0.00411423 - accuracy  1.0\n",
      "epoch:  1168  - cost 0.00410515 - accuracy  1.0\n",
      "epoch:  1169  - cost 0.00409015 - accuracy  1.0\n",
      "epoch:  1170  - cost 0.00408124 - accuracy  1.0\n",
      "epoch:  1171  - cost 0.00405966 - accuracy  1.0\n",
      "epoch:  1172  - cost 0.00405121 - accuracy  1.0\n",
      "epoch:  1173  - cost 0.00402742 - accuracy  1.0\n",
      "epoch:  1174  - cost 0.00401708 - accuracy  1.0\n",
      "epoch:  1175  - cost 0.00400456 - accuracy  1.0\n",
      "epoch:  1176  - cost 0.00398892 - accuracy  1.0\n",
      "epoch:  1177  - cost 0.00397657 - accuracy  1.0\n",
      "epoch:  1178  - cost 0.00395765 - accuracy  1.0\n",
      "epoch:  1179  - cost 0.00395078 - accuracy  1.0\n",
      "epoch:  1180  - cost 0.00393672 - accuracy  1.0\n",
      "epoch:  1181  - cost 0.00392608 - accuracy  1.0\n",
      "epoch:  1182  - cost 0.00390422 - accuracy  1.0\n",
      "epoch:  1183  - cost 0.00389542 - accuracy  1.0\n",
      "epoch:  1184  - cost 0.00388182 - accuracy  1.0\n",
      "epoch:  1185  - cost 0.00386599 - accuracy  1.0\n",
      "epoch:  1186  - cost 0.0038556 - accuracy  1.0\n",
      "epoch:  1187  - cost 0.00384317 - accuracy  1.0\n",
      "epoch:  1188  - cost 0.00383173 - accuracy  1.0\n",
      "epoch:  1189  - cost 0.00381618 - accuracy  1.0\n",
      "epoch:  1190  - cost 0.00381162 - accuracy  1.0\n",
      "epoch:  1191  - cost 0.00379107 - accuracy  1.0\n",
      "epoch:  1192  - cost 0.00378436 - accuracy  1.0\n",
      "epoch:  1193  - cost 0.00376402 - accuracy  1.0\n",
      "epoch:  1194  - cost 0.0037552 - accuracy  1.0\n",
      "epoch:  1195  - cost 0.00374423 - accuracy  1.0\n",
      "epoch:  1196  - cost 0.00373405 - accuracy  1.0\n",
      "epoch:  1197  - cost 0.00372009 - accuracy  1.0\n",
      "epoch:  1198  - cost 0.00371129 - accuracy  1.0\n",
      "epoch:  1199  - cost 0.00369075 - accuracy  1.0\n",
      "epoch:  1200  - cost 0.00368272 - accuracy  1.0\n",
      "epoch:  1201  - cost 0.00367342 - accuracy  1.0\n",
      "epoch:  1202  - cost 0.00365611 - accuracy  1.0\n",
      "epoch:  1203  - cost 0.00364708 - accuracy  1.0\n",
      "epoch:  1204  - cost 0.00363186 - accuracy  1.0\n",
      "epoch:  1205  - cost 0.00362414 - accuracy  1.0\n",
      "epoch:  1206  - cost 0.00360793 - accuracy  1.0\n",
      "epoch:  1207  - cost 0.00359793 - accuracy  1.0\n",
      "epoch:  1208  - cost 0.00358321 - accuracy  1.0\n",
      "epoch:  1209  - cost 0.00357404 - accuracy  1.0\n",
      "epoch:  1210  - cost 0.00356006 - accuracy  1.0\n",
      "epoch:  1211  - cost 0.00355475 - accuracy  1.0\n",
      "epoch:  1212  - cost 0.00354271 - accuracy  1.0\n",
      "epoch:  1213  - cost 0.00353121 - accuracy  1.0\n",
      "epoch:  1214  - cost 0.00351518 - accuracy  1.0\n",
      "epoch:  1215  - cost 0.00350706 - accuracy  1.0\n",
      "epoch:  1216  - cost 0.00349236 - accuracy  1.0\n",
      "epoch:  1217  - cost 0.00348357 - accuracy  1.0\n",
      "epoch:  1218  - cost 0.00346925 - accuracy  1.0\n",
      "epoch:  1219  - cost 0.00345851 - accuracy  1.0\n",
      "epoch:  1220  - cost 0.00345258 - accuracy  1.0\n",
      "epoch:  1221  - cost 0.00343917 - accuracy  1.0\n",
      "epoch:  1222  - cost 0.00342922 - accuracy  1.0\n",
      "epoch:  1223  - cost 0.00341369 - accuracy  1.0\n",
      "epoch:  1224  - cost 0.00341001 - accuracy  1.0\n",
      "epoch:  1225  - cost 0.00339495 - accuracy  1.0\n",
      "epoch:  1226  - cost 0.00338471 - accuracy  1.0\n",
      "epoch:  1227  - cost 0.0033718 - accuracy  1.0\n",
      "epoch:  1228  - cost 0.0033646 - accuracy  1.0\n",
      "epoch:  1229  - cost 0.00335035 - accuracy  1.0\n",
      "epoch:  1230  - cost 0.00333909 - accuracy  1.0\n",
      "epoch:  1231  - cost 0.00332918 - accuracy  1.0\n",
      "epoch:  1232  - cost 0.00331952 - accuracy  1.0\n",
      "epoch:  1233  - cost 0.00331299 - accuracy  1.0\n",
      "epoch:  1234  - cost 0.00329806 - accuracy  1.0\n",
      "epoch:  1235  - cost 0.00328819 - accuracy  1.0\n",
      "epoch:  1236  - cost 0.00327824 - accuracy  1.0\n",
      "epoch:  1237  - cost 0.00327008 - accuracy  1.0\n",
      "epoch:  1238  - cost 0.0032583 - accuracy  1.0\n",
      "epoch:  1239  - cost 0.00325205 - accuracy  1.0\n",
      "epoch:  1240  - cost 0.00323939 - accuracy  1.0\n",
      "epoch:  1241  - cost 0.00323186 - accuracy  1.0\n",
      "epoch:  1242  - cost 0.00321865 - accuracy  1.0\n",
      "epoch:  1243  - cost 0.00321328 - accuracy  1.0\n",
      "epoch:  1244  - cost 0.00319819 - accuracy  1.0\n",
      "epoch:  1245  - cost 0.00318947 - accuracy  1.0\n",
      "epoch:  1246  - cost 0.00318036 - accuracy  1.0\n",
      "epoch:  1247  - cost 0.00317755 - accuracy  1.0\n",
      "epoch:  1248  - cost 0.00316171 - accuracy  1.0\n",
      "epoch:  1249  - cost 0.00315632 - accuracy  1.0\n",
      "epoch:  1250  - cost 0.00314331 - accuracy  1.0\n",
      "epoch:  1251  - cost 0.00313824 - accuracy  1.0\n",
      "epoch:  1252  - cost 0.00312314 - accuracy  1.0\n",
      "epoch:  1253  - cost 0.00311798 - accuracy  1.0\n",
      "epoch:  1254  - cost 0.00311108 - accuracy  1.0\n",
      "epoch:  1255  - cost 0.00309761 - accuracy  1.0\n",
      "epoch:  1256  - cost 0.00308933 - accuracy  1.0\n",
      "epoch:  1257  - cost 0.00308225 - accuracy  1.0\n",
      "epoch:  1258  - cost 0.00307476 - accuracy  1.0\n",
      "epoch:  1259  - cost 0.00306232 - accuracy  1.0\n",
      "epoch:  1260  - cost 0.00305441 - accuracy  1.0\n",
      "epoch:  1261  - cost 0.00304495 - accuracy  1.0\n",
      "epoch:  1262  - cost 0.00303785 - accuracy  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1263  - cost 0.00302862 - accuracy  1.0\n",
      "epoch:  1264  - cost 0.00302478 - accuracy  1.0\n",
      "epoch:  1265  - cost 0.00301101 - accuracy  1.0\n",
      "epoch:  1266  - cost 0.00300329 - accuracy  1.0\n",
      "epoch:  1267  - cost 0.00299336 - accuracy  1.0\n",
      "epoch:  1268  - cost 0.00298675 - accuracy  1.0\n",
      "epoch:  1269  - cost 0.0029777 - accuracy  1.0\n",
      "epoch:  1270  - cost 0.00297264 - accuracy  1.0\n",
      "epoch:  1271  - cost 0.00296103 - accuracy  1.0\n",
      "epoch:  1272  - cost 0.00295424 - accuracy  1.0\n",
      "epoch:  1273  - cost 0.00294391 - accuracy  1.0\n",
      "epoch:  1274  - cost 0.00293829 - accuracy  1.0\n",
      "epoch:  1275  - cost 0.00292857 - accuracy  1.0\n",
      "epoch:  1276  - cost 0.00292294 - accuracy  1.0\n",
      "epoch:  1277  - cost 0.00291248 - accuracy  1.0\n",
      "epoch:  1278  - cost 0.00290512 - accuracy  1.0\n",
      "epoch:  1279  - cost 0.00289667 - accuracy  1.0\n",
      "epoch:  1280  - cost 0.002892 - accuracy  1.0\n",
      "epoch:  1281  - cost 0.00288039 - accuracy  1.0\n",
      "epoch:  1282  - cost 0.00287366 - accuracy  1.0\n",
      "epoch:  1283  - cost 0.00286787 - accuracy  1.0\n",
      "epoch:  1284  - cost 0.0028619 - accuracy  1.0\n",
      "epoch:  1285  - cost 0.00285016 - accuracy  1.0\n",
      "epoch:  1286  - cost 0.0028433 - accuracy  1.0\n",
      "epoch:  1287  - cost 0.00283696 - accuracy  1.0\n",
      "epoch:  1288  - cost 0.00283191 - accuracy  1.0\n",
      "epoch:  1289  - cost 0.00281953 - accuracy  1.0\n",
      "epoch:  1290  - cost 0.00281496 - accuracy  1.0\n",
      "epoch:  1291  - cost 0.00280939 - accuracy  1.0\n",
      "epoch:  1292  - cost 0.00279918 - accuracy  1.0\n",
      "epoch:  1293  - cost 0.00279183 - accuracy  1.0\n",
      "epoch:  1294  - cost 0.00278485 - accuracy  1.0\n",
      "epoch:  1295  - cost 0.00277931 - accuracy  1.0\n",
      "epoch:  1296  - cost 0.0027694 - accuracy  1.0\n",
      "epoch:  1297  - cost 0.00276335 - accuracy  1.0\n",
      "epoch:  1298  - cost 0.00275574 - accuracy  1.0\n",
      "epoch:  1299  - cost 0.0027496 - accuracy  1.0\n",
      "epoch:  1300  - cost 0.00274272 - accuracy  1.0\n",
      "epoch:  1301  - cost 0.00273644 - accuracy  1.0\n",
      "epoch:  1302  - cost 0.00272916 - accuracy  1.0\n",
      "epoch:  1303  - cost 0.00272595 - accuracy  1.0\n",
      "epoch:  1304  - cost 0.00271364 - accuracy  1.0\n",
      "epoch:  1305  - cost 0.00270632 - accuracy  1.0\n",
      "epoch:  1306  - cost 0.00270159 - accuracy  1.0\n",
      "epoch:  1307  - cost 0.00269683 - accuracy  1.0\n",
      "epoch:  1308  - cost 0.00268694 - accuracy  1.0\n",
      "epoch:  1309  - cost 0.00267924 - accuracy  1.0\n",
      "epoch:  1310  - cost 0.00267484 - accuracy  1.0\n",
      "epoch:  1311  - cost 0.00266878 - accuracy  1.0\n",
      "epoch:  1312  - cost 0.00265942 - accuracy  1.0\n",
      "epoch:  1313  - cost 0.00265205 - accuracy  1.0\n",
      "epoch:  1314  - cost 0.00264684 - accuracy  1.0\n",
      "epoch:  1315  - cost 0.00264183 - accuracy  1.0\n",
      "epoch:  1316  - cost 0.00263224 - accuracy  1.0\n",
      "epoch:  1317  - cost 0.00262514 - accuracy  1.0\n",
      "epoch:  1318  - cost 0.00261764 - accuracy  1.0\n",
      "epoch:  1319  - cost 0.00261196 - accuracy  1.0\n",
      "epoch:  1320  - cost 0.00260458 - accuracy  1.0\n",
      "epoch:  1321  - cost 0.00259849 - accuracy  1.0\n",
      "epoch:  1322  - cost 0.00259269 - accuracy  1.0\n",
      "epoch:  1323  - cost 0.00258627 - accuracy  1.0\n",
      "epoch:  1324  - cost 0.0025777 - accuracy  1.0\n",
      "epoch:  1325  - cost 0.0025709 - accuracy  1.0\n",
      "epoch:  1326  - cost 0.00256574 - accuracy  1.0\n",
      "epoch:  1327  - cost 0.00255901 - accuracy  1.0\n",
      "epoch:  1328  - cost 0.00255082 - accuracy  1.0\n",
      "epoch:  1329  - cost 0.00254559 - accuracy  1.0\n",
      "epoch:  1330  - cost 0.00253809 - accuracy  1.0\n",
      "epoch:  1331  - cost 0.00253201 - accuracy  1.0\n",
      "epoch:  1332  - cost 0.00252416 - accuracy  1.0\n",
      "epoch:  1333  - cost 0.00251798 - accuracy  1.0\n",
      "epoch:  1334  - cost 0.00251094 - accuracy  1.0\n",
      "epoch:  1335  - cost 0.00250323 - accuracy  1.0\n",
      "epoch:  1336  - cost 0.00249647 - accuracy  1.0\n",
      "epoch:  1337  - cost 0.00249143 - accuracy  1.0\n",
      "epoch:  1338  - cost 0.00248798 - accuracy  1.0\n",
      "epoch:  1339  - cost 0.00247867 - accuracy  1.0\n",
      "epoch:  1340  - cost 0.00247211 - accuracy  1.0\n",
      "epoch:  1341  - cost 0.00246592 - accuracy  1.0\n",
      "epoch:  1342  - cost 0.00246244 - accuracy  1.0\n",
      "epoch:  1343  - cost 0.0024536 - accuracy  1.0\n",
      "epoch:  1344  - cost 0.0024477 - accuracy  1.0\n",
      "epoch:  1345  - cost 0.00244124 - accuracy  1.0\n",
      "epoch:  1346  - cost 0.00243697 - accuracy  1.0\n",
      "epoch:  1347  - cost 0.00242907 - accuracy  1.0\n",
      "epoch:  1348  - cost 0.00242455 - accuracy  1.0\n",
      "epoch:  1349  - cost 0.00241756 - accuracy  1.0\n",
      "epoch:  1350  - cost 0.00241182 - accuracy  1.0\n",
      "epoch:  1351  - cost 0.00240583 - accuracy  1.0\n",
      "epoch:  1352  - cost 0.00239968 - accuracy  1.0\n",
      "epoch:  1353  - cost 0.00239425 - accuracy  1.0\n",
      "epoch:  1354  - cost 0.00238862 - accuracy  1.0\n",
      "epoch:  1355  - cost 0.00238197 - accuracy  1.0\n",
      "epoch:  1356  - cost 0.00237523 - accuracy  1.0\n",
      "epoch:  1357  - cost 0.00236858 - accuracy  1.0\n",
      "epoch:  1358  - cost 0.00236427 - accuracy  1.0\n",
      "epoch:  1359  - cost 0.00235977 - accuracy  1.0\n",
      "epoch:  1360  - cost 0.00235288 - accuracy  1.0\n",
      "epoch:  1361  - cost 0.00234826 - accuracy  1.0\n",
      "epoch:  1362  - cost 0.00234195 - accuracy  1.0\n",
      "epoch:  1363  - cost 0.0023363 - accuracy  1.0\n",
      "epoch:  1364  - cost 0.00232947 - accuracy  1.0\n",
      "epoch:  1365  - cost 0.00232376 - accuracy  1.0\n",
      "epoch:  1366  - cost 0.00231883 - accuracy  1.0\n",
      "epoch:  1367  - cost 0.00231435 - accuracy  1.0\n",
      "epoch:  1368  - cost 0.00230736 - accuracy  1.0\n",
      "epoch:  1369  - cost 0.00230284 - accuracy  1.0\n",
      "epoch:  1370  - cost 0.00229685 - accuracy  1.0\n",
      "epoch:  1371  - cost 0.00229182 - accuracy  1.0\n",
      "epoch:  1372  - cost 0.00228591 - accuracy  1.0\n",
      "epoch:  1373  - cost 0.00227981 - accuracy  1.0\n",
      "epoch:  1374  - cost 0.002275 - accuracy  1.0\n",
      "epoch:  1375  - cost 0.00226926 - accuracy  1.0\n",
      "epoch:  1376  - cost 0.00226395 - accuracy  1.0\n",
      "epoch:  1377  - cost 0.0022601 - accuracy  1.0\n",
      "epoch:  1378  - cost 0.00225598 - accuracy  1.0\n",
      "epoch:  1379  - cost 0.00224909 - accuracy  1.0\n",
      "epoch:  1380  - cost 0.00224387 - accuracy  1.0\n",
      "epoch:  1381  - cost 0.0022391 - accuracy  1.0\n",
      "epoch:  1382  - cost 0.00223432 - accuracy  1.0\n",
      "epoch:  1383  - cost 0.0022292 - accuracy  1.0\n",
      "epoch:  1384  - cost 0.00222385 - accuracy  1.0\n",
      "epoch:  1385  - cost 0.00222033 - accuracy  1.0\n",
      "epoch:  1386  - cost 0.00221641 - accuracy  1.0\n",
      "epoch:  1387  - cost 0.00221117 - accuracy  1.0\n",
      "epoch:  1388  - cost 0.00220587 - accuracy  1.0\n",
      "epoch:  1389  - cost 0.00220087 - accuracy  1.0\n",
      "epoch:  1390  - cost 0.0021957 - accuracy  1.0\n",
      "epoch:  1391  - cost 0.00219117 - accuracy  1.0\n",
      "epoch:  1392  - cost 0.00218694 - accuracy  1.0\n",
      "epoch:  1393  - cost 0.00218266 - accuracy  1.0\n",
      "epoch:  1394  - cost 0.0021778 - accuracy  1.0\n",
      "epoch:  1395  - cost 0.00217344 - accuracy  1.0\n",
      "epoch:  1396  - cost 0.00216756 - accuracy  1.0\n",
      "epoch:  1397  - cost 0.00216315 - accuracy  1.0\n",
      "epoch:  1398  - cost 0.00215869 - accuracy  1.0\n",
      "epoch:  1399  - cost 0.00215674 - accuracy  1.0\n",
      "epoch:  1400  - cost 0.00215055 - accuracy  1.0\n",
      "epoch:  1401  - cost 0.00214527 - accuracy  1.0\n",
      "epoch:  1402  - cost 0.00214128 - accuracy  1.0\n",
      "epoch:  1403  - cost 0.0021381 - accuracy  1.0\n",
      "epoch:  1404  - cost 0.00213195 - accuracy  1.0\n",
      "epoch:  1405  - cost 0.00212714 - accuracy  1.0\n",
      "epoch:  1406  - cost 0.00212357 - accuracy  1.0\n",
      "epoch:  1407  - cost 0.00211985 - accuracy  1.0\n",
      "epoch:  1408  - cost 0.00211541 - accuracy  1.0\n",
      "epoch:  1409  - cost 0.00211069 - accuracy  1.0\n",
      "epoch:  1410  - cost 0.00210555 - accuracy  1.0\n",
      "epoch:  1411  - cost 0.00210118 - accuracy  1.0\n",
      "epoch:  1412  - cost 0.00209758 - accuracy  1.0\n",
      "epoch:  1413  - cost 0.00209396 - accuracy  1.0\n",
      "epoch:  1414  - cost 0.00208948 - accuracy  1.0\n",
      "epoch:  1415  - cost 0.00208508 - accuracy  1.0\n",
      "epoch:  1416  - cost 0.0020805 - accuracy  1.0\n",
      "epoch:  1417  - cost 0.00207659 - accuracy  1.0\n",
      "epoch:  1418  - cost 0.00207281 - accuracy  1.0\n",
      "epoch:  1419  - cost 0.00206796 - accuracy  1.0\n",
      "epoch:  1420  - cost 0.00206431 - accuracy  1.0\n",
      "epoch:  1421  - cost 0.00205977 - accuracy  1.0\n",
      "epoch:  1422  - cost 0.00205544 - accuracy  1.0\n",
      "epoch:  1423  - cost 0.00205114 - accuracy  1.0\n",
      "epoch:  1424  - cost 0.00204742 - accuracy  1.0\n",
      "epoch:  1425  - cost 0.00204243 - accuracy  1.0\n",
      "epoch:  1426  - cost 0.00203884 - accuracy  1.0\n",
      "epoch:  1427  - cost 0.00203575 - accuracy  1.0\n",
      "epoch:  1428  - cost 0.00203196 - accuracy  1.0\n",
      "epoch:  1429  - cost 0.00202741 - accuracy  1.0\n",
      "epoch:  1430  - cost 0.00202348 - accuracy  1.0\n",
      "epoch:  1431  - cost 0.00202035 - accuracy  1.0\n",
      "epoch:  1432  - cost 0.00201587 - accuracy  1.0\n",
      "epoch:  1433  - cost 0.00201135 - accuracy  1.0\n",
      "epoch:  1434  - cost 0.00200755 - accuracy  1.0\n",
      "epoch:  1435  - cost 0.0020027 - accuracy  1.0\n",
      "epoch:  1436  - cost 0.00199946 - accuracy  1.0\n",
      "epoch:  1437  - cost 0.00199696 - accuracy  1.0\n",
      "epoch:  1438  - cost 0.00199364 - accuracy  1.0\n",
      "epoch:  1439  - cost 0.00198812 - accuracy  1.0\n",
      "epoch:  1440  - cost 0.00198383 - accuracy  1.0\n",
      "epoch:  1441  - cost 0.00198095 - accuracy  1.0\n",
      "epoch:  1442  - cost 0.00197822 - accuracy  1.0\n",
      "epoch:  1443  - cost 0.00197286 - accuracy  1.0\n",
      "epoch:  1444  - cost 0.00196826 - accuracy  1.0\n",
      "epoch:  1445  - cost 0.00196511 - accuracy  1.0\n",
      "epoch:  1446  - cost 0.00196225 - accuracy  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1447  - cost 0.00196025 - accuracy  1.0\n",
      "epoch:  1448  - cost 0.00195436 - accuracy  1.0\n",
      "epoch:  1449  - cost 0.00195025 - accuracy  1.0\n",
      "epoch:  1450  - cost 0.00194679 - accuracy  1.0\n",
      "epoch:  1451  - cost 0.00194436 - accuracy  1.0\n",
      "epoch:  1452  - cost 0.00193981 - accuracy  1.0\n",
      "epoch:  1453  - cost 0.00193641 - accuracy  1.0\n",
      "epoch:  1454  - cost 0.00193311 - accuracy  1.0\n",
      "epoch:  1455  - cost 0.00193157 - accuracy  1.0\n",
      "epoch:  1456  - cost 0.00192551 - accuracy  1.0\n",
      "epoch:  1457  - cost 0.00192157 - accuracy  1.0\n",
      "epoch:  1458  - cost 0.00191842 - accuracy  1.0\n",
      "epoch:  1459  - cost 0.00191524 - accuracy  1.0\n",
      "epoch:  1460  - cost 0.00191133 - accuracy  1.0\n",
      "epoch:  1461  - cost 0.00190762 - accuracy  1.0\n",
      "epoch:  1462  - cost 0.00190453 - accuracy  1.0\n",
      "epoch:  1463  - cost 0.0019023 - accuracy  1.0\n",
      "epoch:  1464  - cost 0.00189712 - accuracy  1.0\n",
      "epoch:  1465  - cost 0.00189356 - accuracy  1.0\n",
      "epoch:  1466  - cost 0.00189085 - accuracy  1.0\n",
      "epoch:  1467  - cost 0.00188842 - accuracy  1.0\n",
      "epoch:  1468  - cost 0.00188324 - accuracy  1.0\n",
      "epoch:  1469  - cost 0.0018801 - accuracy  1.0\n",
      "epoch:  1470  - cost 0.00187693 - accuracy  1.0\n",
      "epoch:  1471  - cost 0.00187386 - accuracy  1.0\n",
      "epoch:  1472  - cost 0.00186974 - accuracy  1.0\n",
      "epoch:  1473  - cost 0.00186589 - accuracy  1.0\n",
      "epoch:  1474  - cost 0.00186263 - accuracy  1.0\n",
      "epoch:  1475  - cost 0.00185971 - accuracy  1.0\n",
      "epoch:  1476  - cost 0.00185721 - accuracy  1.0\n",
      "epoch:  1477  - cost 0.00185538 - accuracy  1.0\n",
      "epoch:  1478  - cost 0.00184942 - accuracy  1.0\n",
      "epoch:  1479  - cost 0.00184578 - accuracy  1.0\n",
      "epoch:  1480  - cost 0.00184426 - accuracy  1.0\n",
      "epoch:  1481  - cost 0.00184145 - accuracy  1.0\n",
      "epoch:  1482  - cost 0.0018367 - accuracy  1.0\n",
      "epoch:  1483  - cost 0.00183308 - accuracy  1.0\n",
      "epoch:  1484  - cost 0.00183038 - accuracy  1.0\n",
      "epoch:  1485  - cost 0.00182699 - accuracy  1.0\n",
      "epoch:  1486  - cost 0.00182399 - accuracy  1.0\n",
      "epoch:  1487  - cost 0.00182182 - accuracy  1.0\n",
      "epoch:  1488  - cost 0.00181739 - accuracy  1.0\n",
      "epoch:  1489  - cost 0.00181358 - accuracy  1.0\n",
      "epoch:  1490  - cost 0.00181105 - accuracy  1.0\n",
      "epoch:  1491  - cost 0.00180749 - accuracy  1.0\n",
      "epoch:  1492  - cost 0.00180477 - accuracy  1.0\n",
      "epoch:  1493  - cost 0.00180162 - accuracy  1.0\n",
      "epoch:  1494  - cost 0.00179822 - accuracy  1.0\n",
      "epoch:  1495  - cost 0.00179591 - accuracy  1.0\n",
      "epoch:  1496  - cost 0.00179294 - accuracy  1.0\n",
      "epoch:  1497  - cost 0.00178952 - accuracy  1.0\n",
      "epoch:  1498  - cost 0.00178575 - accuracy  1.0\n",
      "epoch:  1499  - cost 0.0017823 - accuracy  1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    training_writer = tf.summary.FileWriter(\"../logs/training\", sess.graph)\n",
    "    for epoch in range(training_epochs):\n",
    "        sess.run(training_step_, feed_dict={x_:Xtrain, yreal_:ytrain})\n",
    "        cost, training_summary = sess.run([cost_function_, summary], feed_dict={x_:Xtrain, yreal_:ytrain})\n",
    "        training_writer.add_summary(training_summary, epoch)\n",
    "        accuracy = sess.run(accuracy_, feed_dict={x_:Xtrain, yreal_:ytrain})\n",
    "        cost_history = np.append(cost_history, cost)\n",
    "        accuracy_history = np.append(accuracy_history, accuracy_)\n",
    "        print(\"epoch: \", epoch, \" - cost\", cost, \"- accuracy \", accuracy)\n",
    "# accuracy on the test set:\n",
    "    sess.run(accuracy_, feed_dict={x_:Xtest, yreal_:ytest})\n",
    "    ypredLabel_ = tf.argmax(ypred_, 1)\n",
    "    ypredLabel = sess.run(ypredLabel_, feed_dict={x_:Xtest})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we evaluate the accuracy of the trained model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytestLabel = np.argmax(ytest, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual  Prediction\n",
       "0        0           1\n",
       "1        0           1\n",
       "2        0           1\n",
       "3        1           1\n",
       "4        0           0\n",
       "5        1           1\n",
       "6        0           0\n",
       "7        0           0\n",
       "8        1           1\n",
       "9        0           0\n",
       "10       1           1\n",
       "11       0           0\n",
       "12       1           1\n",
       "13       0           0\n",
       "14       1           1\n",
       "15       1           1\n",
       "16       0           0\n",
       "17       1           1\n",
       "18       1           1\n",
       "19       1           1\n",
       "20       0           0\n",
       "21       1           1\n",
       "22       0           1\n",
       "23       1           1\n",
       "24       1           1\n",
       "25       0           0\n",
       "26       0           0\n",
       "27       0           0\n",
       "28       0           0\n",
       "29       0           0\n",
       "30       1           1\n",
       "31       0           0\n",
       "32       1           0\n",
       "33       1           1\n",
       "34       0           0\n",
       "35       0           0\n",
       "36       0           0\n",
       "37       0           0\n",
       "38       1           1\n",
       "39       0           0\n",
       "40       0           0\n",
       "41       0           1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.transpose([ypredLabel, ytestLabel]), columns=['Actual', 'Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
